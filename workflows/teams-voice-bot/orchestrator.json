{
  "updatedAt": "2026-01-10T00:46:18.228Z",
  "createdAt": "2025-12-27T04:48:10.416Z",
  "id": "d3CxEaYk5mkC8sLo",
  "name": "Teams Voice Bot v3.0 - Agent Orchestrator",
  "description": null,
  "active": true,
  "isArchived": false,
  "nodes": [
    {
      "parameters": {
        "httpMethod": "POST",
        "path": "voice-bot-v3",
        "responseMode": "onReceived",
        "options": {}
      },
      "id": "webhook-1",
      "name": "Webhook",
      "type": "n8n-nodes-base.webhook",
      "position": [
        0,
        304
      ],
      "webhookId": "voice-bot-v3",
      "typeVersion": 2.1
    },
    {
      "parameters": {
        "mode": "runOnceForEachItem",
        "jsCode": "// CONSOLIDATED: Parse + Extract + Classify + Response Timing + DEDUPLICATION v4\n// ENHANCED: Added Streaming Context Protocol - caches session context to avoid redundant DB loads\nconst item = $input.item.json;\nconst body = item.body || {};\nconst data = body.data || {};\nconst inner = data.data || {};\nconst words = inner.words || [];\nconst participant = inner.participant || {};\nconst bot = data.bot || {};\n\n// Early exit if no words\nif (!Array.isArray(words) || words.length === 0) {\n  return {\n    json: {\n      route: 'NO_TRANSCRIPT',\n      event_type: body.event || 'unknown',\n      bot_id: bot.id || 'unknown',\n      transcript: '',\n      is_final: false,\n      speaker: 'unknown',\n      speaker_id: null,\n      is_host: false,\n      received_at: Date.now(),\n      intent: 'no_content',\n      should_respond: false,\n      is_addressing_bot: false,\n      is_first_message: false,\n      response_timing: { is_complete_thought: false, response_urgency: 'none' },\n      session_state: { last_orchestrator_cues: '', pending_actions: [], processing_count: 0 },\n      classified_at: new Date().toISOString(),\n      dedup: { is_duplicate: false, reason: 'no_words' },\n      // Streaming Context Protocol fields\n      use_cached_context: false,\n      cached_history: [],\n      accumulated_transcript: '',\n      context_age_ms: 0,\n      chunk_number: 0\n    }\n  };\n}\n\nconst transcript = words.map(w => w.text).join(' ').trim();\nconst speaker = participant.name || 'unknown';\nconst bot_id = bot.id || 'unknown';\n\n// === SESSION STATE & DEDUPLICATION v4 + STREAMING CONTEXT PROTOCOL ===\nconst staticData = $getWorkflowStaticData('global');\nconst now = Date.now();\n\nif (!staticData.botTranscripts) staticData.botTranscripts = {};\nif (!staticData.botTranscripts[bot_id]) {\n  staticData.botTranscripts[bot_id] = {\n    // Existing fields\n    lastProcessedTranscript: '',\n    lastProcessedTime: 0,\n    processingCount: 0,\n    sessionStartTime: now,\n    lastOrchestratorCues: '',\n    pendingActions: [],\n\n    // NEW: Streaming Context Protocol fields\n    cachedHistory: [],              // Cached DB rows\n    cachedHistoryTime: 0,           // When cache was populated\n    accumulatedTranscript: '',      // All chunks this session\n    chunkNumber: 0,                 // Current chunk count\n    lastRouteDecision: '',          // Track route changes\n    contextValid: false             // Whether cache is usable\n  };\n}\n\nconst botState = staticData.botTranscripts[bot_id];\nconst lastTranscript = botState.lastProcessedTranscript;\nconst timeSinceLastProcess = now - botState.lastProcessedTime;\n\n// Increment chunk number\nbotState.chunkNumber++;\nconst currentChunkNumber = botState.chunkNumber;\n\n// First message detection (no prior processing OR > 5 min inactive)\nconst isFirstMessage = botState.processingCount === 0 || timeSinceLastProcess > 300000;\nif (isFirstMessage && timeSinceLastProcess > 300000) {\n  // Session reset - invalidate cache\n  botState.sessionStartTime = now;\n  botState.processingCount = 0;\n  botState.lastOrchestratorCues = '';\n  botState.pendingActions = [];\n  botState.cachedHistory = [];\n  botState.cachedHistoryTime = 0;\n  botState.accumulatedTranscript = '';\n  botState.chunkNumber = 1;\n  botState.lastRouteDecision = '';\n  botState.contextValid = false;\n}\n\n// Deduplication\nlet isDuplicate = false, isExtension = false, dedupReason = 'new_content';\nif (lastTranscript && timeSinceLastProcess < 15000) {\n  const currentLower = transcript.toLowerCase().trim();\n  const lastLower = lastTranscript.toLowerCase().trim();\n  if (currentLower === lastLower) {\n    isDuplicate = true;\n    dedupReason = 'exact_duplicate';\n  } else if (currentLower.startsWith(lastLower) || lastLower.startsWith(currentLower)) {\n    isExtension = true;\n    dedupReason = currentLower.startsWith(lastLower) ? 'extension_of_previous' : 'subset_of_previous';\n  }\n}\n\n// === RESPONSE TIMING ===\nconst hasEndPunctuation = /[.!?]$/.test(transcript);\nconst wordCount = words.length;\nlet speakingDurationMs = 0;\nif (words.length >= 2) {\n  const f = words[0], l = words[words.length - 1];\n  if (f.start_timestamp?.relative && l.end_timestamp?.relative) {\n    speakingDurationMs = (l.end_timestamp.relative - f.start_timestamp.relative) * 1000;\n  }\n}\n\nconst lowerTranscript = transcript.toLowerCase();\nconst isFromHuman = !['bot', 'assistant'].includes(speaker.toLowerCase());\n\n// PHONETIC bot name detection\nconst botPatterns = [\n  /\\b(synergy|synrg)\\s*bot\\b/i, /\\bsynergy\\b/i, /\\bsynrg\\b/i,\n  /\\bsin\\s*urge\\s*y?\\b/i, /\\bsin\\s*ergy\\b/i, /\\bcin\\s*ergy\\b/i, /\\bsen\\s*ergy\\b/i,\n  /\\bhey\\s+(synergy|synrg|sin\\s*ergy)\\b/i,\n  /\\b(bot|assistant|ai|hey\\s*bot|hello\\s*bot|voice\\s*bot)\\b/i\n];\nconst isAddressingBot = botPatterns.some(p => p.test(lowerTranscript));\n\nconst emailPatterns = /send\\s*(an\\s*)?email|email\\s*to|compose\\s*email|write\\s*(an\\s*)?email/i;\nconst questionPatterns = /\\?$|what|how|when|where|why|can you|could you|tell me|explain/i;\nconst greetingPatterns = /^(hi|hello|hey|good morning|good afternoon|good evening)/i;\nconst commandPatterns = /please|help|need|want|could you|can you|would you/i;\n\n// Complete thought detection (voice-friendly, no punctuation required)\nlet isCompleteThought = false, responseUrgency = 'none';\nif (hasEndPunctuation && wordCount >= 4) {\n  isCompleteThought = true; responseUrgency = 'standard';\n} else if (wordCount >= 10) {\n  isCompleteThought = true; responseUrgency = 'standard';\n} else if (wordCount >= 5 && isAddressingBot) {\n  isCompleteThought = true; responseUrgency = 'immediate';\n} else if (wordCount >= 5 && (emailPatterns.test(lowerTranscript) || commandPatterns.test(lowerTranscript))) {\n  isCompleteThought = true; responseUrgency = 'standard';\n} else if (wordCount < 4) {\n  isCompleteThought = false; responseUrgency = 'wait';\n}\n\nif (isFirstMessage && greetingPatterns.test(lowerTranscript) && wordCount >= 2) {\n  isCompleteThought = true; responseUrgency = 'immediate';\n}\n\nlet route = 'SILENT', intent = 'no_content', shouldRespond = false;\nconst isFinal = isCompleteThought;\n\nif (isDuplicate) {\n  route = 'SILENT'; intent = 'duplicate_skipped';\n} else if (isExtension) {\n  route = 'WAIT_LOG'; intent = 'partial_extension';\n} else if (isFromHuman && isCompleteThought) {\n  const requiresResponse = isAddressingBot ||\n    emailPatterns.test(lowerTranscript) ||\n    (questionPatterns.test(lowerTranscript) && commandPatterns.test(lowerTranscript)) ||\n    (greetingPatterns.test(lowerTranscript) && isFirstMessage);\n\n  if (requiresResponse) {\n    route = 'PROCESS'; shouldRespond = true;\n    intent = emailPatterns.test(lowerTranscript) ? 'email_request' :\n             (greetingPatterns.test(lowerTranscript) && isFirstMessage) ? 'first_greeting' :\n             questionPatterns.test(lowerTranscript) ? 'question' :\n             greetingPatterns.test(lowerTranscript) ? 'greeting' :\n             isAddressingBot ? 'addressing_bot' : 'command';\n    botState.lastProcessedTranscript = transcript;\n    botState.lastProcessedTime = now;\n    botState.processingCount++;\n  } else {\n    route = 'LISTEN'; intent = 'general_speech';\n  }\n} else if (!isCompleteThought && transcript.length > 0) {\n  route = 'WAIT_LOG'; intent = 'partial_transcript';\n}\n\n// === STREAMING CONTEXT PROTOCOL: Cache Management ===\n\n// Accumulate transcript chunks\nif (!isFirstMessage) {\n  botState.accumulatedTranscript += (botState.accumulatedTranscript ? ' ' : '') + transcript;\n} else {\n  botState.accumulatedTranscript = transcript;\n}\n\n// Calculate context age\nconst contextAge = botState.cachedHistoryTime > 0 ? now - botState.cachedHistoryTime : 0;\n\n// Cache invalidation conditions\nconst CACHE_MAX_AGE_MS = 30000; // 30 seconds\nconst cacheIsTooOld = contextAge > CACHE_MAX_AGE_MS;\nconst routeChangedToProcess = route === 'PROCESS' && botState.lastRouteDecision !== 'PROCESS';\nconst shouldInvalidateCache = isFirstMessage || cacheIsTooOld || routeChangedToProcess;\n\n// Determine if we should use cached context or load fresh from DB\nlet useCachedContext = false;\nlet cachedHistory = [];\n\nif (!shouldInvalidateCache && botState.contextValid && botState.cachedHistory.length > 0) {\n  // Cache is valid and fresh - use it\n  useCachedContext = true;\n  cachedHistory = botState.cachedHistory;\n} else {\n  // Cache is invalid - downstream should load fresh from DB\n  useCachedContext = false;\n  cachedHistory = [];\n  botState.contextValid = false; // Mark cache as needing refresh\n}\n\n// Update last route decision\nbotState.lastRouteDecision = route;\n\nreturn {\n  json: {\n    bot_id, transcript, is_final: isFinal, speaker,\n    speaker_id: participant.id || null, is_host: participant.is_host || false,\n    received_at: Date.now(), event_type: body.event || 'unknown',\n    route, intent, should_respond: shouldRespond,\n    is_addressing_bot: isAddressingBot, is_first_message: isFirstMessage,\n    response_timing: { is_complete_thought: isCompleteThought, has_end_punctuation: hasEndPunctuation, word_count: wordCount, speaking_duration_ms: speakingDurationMs, response_urgency: responseUrgency },\n    session_state: { last_orchestrator_cues: botState.lastOrchestratorCues, pending_actions: botState.pendingActions, processing_count: botState.processingCount, session_start_time: botState.sessionStartTime },\n    dedup: { is_duplicate: isDuplicate, is_extension: isExtension, reason: dedupReason, last_processed: lastTranscript, time_since_last_ms: timeSinceLastProcess, processing_count: botState.processingCount },\n    classified_at: new Date().toISOString(),\n\n    // NEW: Streaming Context Protocol output fields\n    use_cached_context: useCachedContext,\n    cached_history: cachedHistory,\n    accumulated_transcript: botState.accumulatedTranscript,\n    context_age_ms: contextAge,\n    chunk_number: currentChunkNumber,\n    cache_invalidation_reason: shouldInvalidateCache ? (\n      isFirstMessage ? 'first_message' :\n      cacheIsTooOld ? 'cache_expired' :\n      routeChangedToProcess ? 'route_changed_to_process' :\n      'unknown'\n    ) : 'cache_valid'\n  }\n};"
      },
      "id": "process-transcript",
      "name": "Process Transcript",
      "type": "n8n-nodes-base.code",
      "position": [
        432,
        496
      ],
      "typeVersion": 2
    },
    {
      "parameters": {
        "rules": {
          "values": [
            {
              "conditions": {
                "options": {
                  "version": 2,
                  "leftValue": "",
                  "caseSensitive": true,
                  "typeValidation": "strict"
                },
                "combinator": "and",
                "conditions": [
                  {
                    "id": "rule-silent",
                    "operator": {
                      "type": "string",
                      "operation": "equals"
                    },
                    "leftValue": "={{ $json.route }}",
                    "rightValue": "SILENT"
                  }
                ]
              },
              "renameOutput": true,
              "outputKey": "SILENT"
            },
            {
              "conditions": {
                "options": {
                  "version": 2,
                  "leftValue": "",
                  "caseSensitive": true,
                  "typeValidation": "strict"
                },
                "combinator": "and",
                "conditions": [
                  {
                    "id": "rule-wait",
                    "operator": {
                      "type": "string",
                      "operation": "equals"
                    },
                    "leftValue": "={{ $json.route }}",
                    "rightValue": "WAIT_LOG"
                  }
                ]
              },
              "renameOutput": true,
              "outputKey": "WAIT_LOG"
            },
            {
              "conditions": {
                "options": {
                  "version": 2,
                  "leftValue": "",
                  "caseSensitive": true,
                  "typeValidation": "strict"
                },
                "combinator": "and",
                "conditions": [
                  {
                    "id": "rule-listen",
                    "operator": {
                      "type": "string",
                      "operation": "equals"
                    },
                    "leftValue": "={{ $json.route }}",
                    "rightValue": "LISTEN"
                  }
                ]
              },
              "renameOutput": true,
              "outputKey": "LISTEN"
            },
            {
              "conditions": {
                "options": {
                  "version": 2,
                  "leftValue": "",
                  "caseSensitive": true,
                  "typeValidation": "strict"
                },
                "combinator": "and",
                "conditions": [
                  {
                    "id": "rule-process",
                    "operator": {
                      "type": "string",
                      "operation": "equals"
                    },
                    "leftValue": "={{ $json.route }}",
                    "rightValue": "PROCESS"
                  }
                ]
              },
              "renameOutput": true,
              "outputKey": "PROCESS"
            },
            {
              "conditions": {
                "options": {
                  "version": 2,
                  "leftValue": "",
                  "caseSensitive": true,
                  "typeValidation": "strict"
                },
                "combinator": "and",
                "conditions": [
                  {
                    "id": "rule-no-transcript",
                    "operator": {
                      "type": "string",
                      "operation": "equals"
                    },
                    "leftValue": "={{ $json.route }}",
                    "rightValue": "NO_TRANSCRIPT"
                  }
                ]
              },
              "renameOutput": true,
              "outputKey": "NO_TRANSCRIPT"
            }
          ]
        },
        "options": {
          "fallbackOutput": "none"
        }
      },
      "id": "route-switch",
      "name": "Route Switch",
      "type": "n8n-nodes-base.switch",
      "typeVersion": 3.2,
      "position": [
        432,
        288
      ]
    },
    {
      "parameters": {
        "operation": "executeQuery",
        "query": "=INSERT INTO transcript_log (bot_id, transcript, speaker, route, intent, is_final, created_at) VALUES ('{{ $json.bot_id }}', '{{ $json.transcript }}', '{{ $json.speaker }}', '{{ $json.route }}', '{{ $json.intent }}', {{ $json.is_final }}, NOW()) RETURNING id",
        "options": {}
      },
      "id": "log-silent-transcript",
      "name": "Log Silent Transcript",
      "type": "n8n-nodes-base.postgres",
      "position": [
        672,
        -80
      ],
      "typeVersion": 2.6,
      "credentials": {
        "postgres": {
          "id": "NI3jbq1U8xPst3j3",
          "name": "MICROSOFT TEAMS AGENT DATTABASE"
        }
      }
    },
    {
      "parameters": {
        "mode": "runOnceForEachItem",
        "jsCode": "const input = $input.item.json;\nreturn {\n  json: {\n    action: 'wait_log',\n    bot_id: input.bot_id,\n    transcript: input.transcript,\n    speaker: input.speaker,\n    intent: input.intent,\n    route: input.route,\n    is_final: input.is_final,\n    logged_at: new Date().toISOString(),\n    message: 'Partial transcript - logged without response'\n  }\n};"
      },
      "id": "wait-log",
      "name": "Wait Log Only",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        672,
        160
      ]
    },
    {
      "parameters": {
        "operation": "executeQuery",
        "query": "=INSERT INTO transcript_log (bot_id, transcript, speaker, route, intent, is_final, created_at) VALUES ('{{ $json.bot_id }}', '{{ $json.transcript }}', '{{ $json.speaker }}', '{{ $json.route }}', '{{ $json.intent }}', {{ $json.is_final }}, NOW()) RETURNING id",
        "options": {}
      },
      "id": "log-wait-transcript",
      "name": "Log Wait Transcript",
      "type": "n8n-nodes-base.postgres",
      "position": [
        880,
        160
      ],
      "typeVersion": 2.6,
      "credentials": {
        "postgres": {
          "id": "NI3jbq1U8xPst3j3",
          "name": "MICROSOFT TEAMS AGENT DATTABASE"
        }
      }
    },
    {
      "parameters": {
        "operation": "executeQuery",
        "query": "=INSERT INTO transcript_log (bot_id, transcript, speaker, route, intent, is_final, created_at) VALUES ('{{ $json.bot_id }}', '{{ $json.transcript }}', '{{ $json.speaker }}', '{{ $json.route }}', '{{ $json.intent }}', {{ $json.is_final }}, NOW()) RETURNING id",
        "options": {}
      },
      "id": "listen-log",
      "name": "Log Listen Transcript",
      "type": "n8n-nodes-base.postgres",
      "typeVersion": 2.6,
      "position": [
        672,
        320
      ],
      "credentials": {
        "postgres": {
          "id": "NI3jbq1U8xPst3j3",
          "name": "MICROSOFT TEAMS AGENT DATTABASE"
        }
      }
    },
    {
      "parameters": {
        "operation": "executeQuery",
        "query": "=SELECT transcript_exact, agent_output_raw, tool_calls, classifier_intent, logged_at\nFROM interaction_logs \nWHERE bot_id = '{{ $json.bot_id }}' \nORDER BY logged_at DESC \nLIMIT 4",
        "options": {}
      },
      "id": "load-state-1",
      "name": "Load Bot State",
      "type": "n8n-nodes-base.postgres",
      "position": [
        672,
        496
      ],
      "typeVersion": 2.6,
      "alwaysOutputData": true,
      "credentials": {
        "postgres": {
          "id": "NI3jbq1U8xPst3j3",
          "name": "MICROSOFT TEAMS AGENT DATTABASE"
        }
      },
      "onError": "continueRegularOutput"
    },
    {
      "parameters": {
        "jsCode": "// BUILD AGENT CONTEXT - v5 with Streaming Context Protocol + Cache Integration\nconst transcript = $('Process Transcript').first().json;\n\n// === STREAMING CONTEXT PROTOCOL: CACHE-AWARE HISTORY LOADING ===\nlet historyRows = [];\nconst staticData = $getWorkflowStaticData('global');\n\nif (transcript.use_cached_context && transcript.cached_history && transcript.cached_history.length > 0) {\n  // CACHE HIT: Use pre-loaded history from Process Transcript\n  historyRows = transcript.cached_history;\n  console.log(`✓ Cache HIT: Using ${historyRows.length} cached rows (age: ${transcript.context_age_ms}ms, chunk ${transcript.chunk_number})`);\n} else {\n  // CACHE MISS: Load from database\n  try {\n    historyRows = $('Load Bot State').all().map(item => item.json);\n    console.log(`✗ Cache MISS: Loaded ${historyRows.length} rows from DB (chunk ${transcript.chunk_number || 1})`);\n    \n    // POPULATE CACHE for next chunk\n    if (staticData.botTranscripts && staticData.botTranscripts[transcript.bot_id]) {\n      const botState = staticData.botTranscripts[transcript.bot_id];\n      botState.cachedHistory = historyRows;\n      botState.cachedHistoryTime = Date.now();\n      botState.contextValid = true;\n      console.log(`→ Cache populated for bot ${transcript.bot_id}`);\n    }\n  } catch (e) {\n    console.error('Failed to load history:', e.message);\n    historyRows = [];\n  }\n}\n\n// === CHUNK CONTEXT AWARENESS ===\nconst chunkNumber = transcript.chunk_number || 1;\nconst accumulatedTranscript = transcript.accumulated_transcript || transcript.transcript;\nconst isFirstChunk = chunkNumber === 1;\n\nlet chunkContext = '';\nif (!isFirstChunk) {\n  // Mid-conversation: Show previous chunks from THIS SESSION\n  const currentChunkText = transcript.transcript || '';\n  const previousChunks = accumulatedTranscript.replace(currentChunkText, '').trim();\n  \n  chunkContext = `\\n\\n## Streaming Context (Chunk ${chunkNumber} of Session)\\n**CRITICAL: This is chunk ${chunkNumber} of an ongoing voice stream.**\\n\\n**Previous parts from THIS session:**\\n\"${previousChunks}\"\\n\\n**Current addition (what just arrived):**\\n\"${currentChunkText}\"\\n\\n**Full accumulated transcript:**\\n\"${accumulatedTranscript}\"\\n\\n**IMPORTANT:**\\n- User is CONTINUING their thought from previous chunks\\n- Do NOT treat this as a new conversation\\n- Do NOT re-greet or re-introduce yourself\\n- Build naturally on the accumulated context\\n- Previous chunks: ${chunkNumber - 1}`;\n} else {\n  chunkContext = `\\n\\n## Session Context\\n**This is the START of a new conversation** (Chunk 1 of session).\\n- Fresh session - greeting appropriate if user greets first\\n- No accumulated transcript yet\\n- First words from user in this session`;\n}\n\n// Extract recent transcripts and responses\nconst recentInteractions = historyRows.slice(0, 4).map(row => ({\n  userSaid: (row.transcript_exact || '').toLowerCase().trim(),\n  botReplied: row.agent_output_raw || ''\n}));\n\n// Build conversation history for context\nlet conversationHistory = '';\nif (recentInteractions.length > 0) {\n  conversationHistory = '\\n\\n## Recent Conversation History (From Database):\\n';\n  recentInteractions.forEach((interaction, i) => {\n    conversationHistory += `${i + 1}. User: \"${interaction.userSaid}\"\\n   You said: \"${interaction.botReplied}\"\\n`;\n  });\n}\n\n// Check for similar recent responses to avoid\nconst recentResponses = recentInteractions.map(i => i.botReplied).filter(r => r);\nconst uniqueResponses = [...new Set(recentResponses)];\n\n// Check if user is continuing same topic\nconst currentLower = transcript.transcript.toLowerCase();\nconst lastUserMessage = recentInteractions[0]?.userSaid || '';\nconst isContinuation = currentLower.includes(lastUserMessage) || lastUserMessage.includes(currentLower);\n\n// Response timing from classifier\nconst timing = transcript.response_timing || {};\nconst urgency = timing.response_urgency || 'standard';\nconst isComplete = timing.is_complete_thought || false;\n\n// Session state from classifier\nconst sessionState = transcript.session_state || {};\nconst isFirstMessage = transcript.is_first_message || false;\nconst processingCount = sessionState.processing_count || 0;\nconst lastOrchestratorCues = sessionState.last_orchestrator_cues || '';\nconst pendingActions = sessionState.pending_actions || [];\n\n// Detect if this is an email request that needs an address\nconst needsEmailAddress = /send.*email|email.*to/i.test(currentLower) &&\n  !/[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\\\.[a-zA-Z]{2,}/.test(currentLower);\n\n// Check if we already asked for email address\nconst alreadyAskedForEmail = recentResponses.some(r =>\n  r.toLowerCase().includes('email address') ||\n  r.toLowerCase().includes('what email') ||\n  r.toLowerCase().includes('send that to')\n);\n\n// Build response guidance\nlet responseGuidance = '';\nif (needsEmailAddress && alreadyAskedForEmail) {\n  responseGuidance = `\\n\\n## IMPORTANT: You already asked for the email address!\\nThe user is still talking. They haven't given you an email address yet.\\nWAIT for them to provide an email address. Do NOT ask again.\\nSay something like: \"I'm ready when you have that email address.\" or \"Just let me know the recipient.\"`;\n} else if (isContinuation) {\n  responseGuidance = `\\n\\n## IMPORTANT: User is continuing their previous message.\\nThis appears to be a continuation of what they were saying.\\nDon't repeat your previous response - acknowledge they're still talking or wait for them to finish.`;\n}\n\n// Build Intent Markers explanation section\nconst intentMarkersSection = `## Understanding Intent Classification\\n\\nA fast classifier has ALREADY evaluated this transcript before reaching you. Here's what it determined:\\n\\n**Route Code:** ${transcript.route || 'unknown'}\\n- P=PROCESS (respond to user), W=WAIT (buffering/incomplete), L=LOG_ONLY (background)\\n\\n**Intent:** ${transcript.intent || 'unknown'}\\n- Detected: ${transcript.is_addressing_bot ? 'Bot is being addressed' : 'General conversation'}\\n\\n**Classification Flags (for reference):**\\nThese 7 binary flags were used to determine routing:\\n1. NEAR_END (1) - Sentence appears complete\\n2. REQUEST (2) - Contains action request\\n3. INCOMPLETE (4) - Partial/unfinished thought\\n4. TOOL_ACTIVE (8) - Action in progress\\n5. GREETING (16) - Opening greeting detected\\n6. BOT_ADDRESSED (32) - Bot name mentioned\\n7. FIRST_MSG (64) - Session start\\n\\nCurrent state: is_first_message=${isFirstMessage}, is_addressing_bot=${transcript.is_addressing_bot || false}`;\n\n// Build Session State section\nconst sessionStateSection = `## Session State (From Previous Chunks)\\n\\n**What you said in previous chunks:**\\n${lastOrchestratorCues ? `\"${lastOrchestratorCues}\"` : '(Nothing yet - this is the first chunk you\\'re responding to)'}\\n\\n**Pending actions from previous chunks:**\\n${pendingActions.length > 0 ? pendingActions.map(a => `- ${a}`).join('\\n') : '(No pending actions)'}\\n\\n**Session metrics:**\\n- Total chunks processed: ${processingCount}\\n- Current chunk number: ${chunkNumber}\\n- Session active: ${sessionState.session_start_time ? 'Yes (started ' + new Date(sessionState.session_start_time).toISOString() + ')' : 'Just starting'}\\n\\n**Continuity instructions:**\\n${lastOrchestratorCues && !isFirstMessage ?\\n`- You previously said: \"${lastOrchestratorCues}\"\\n- Build naturally on that response\\n- Don't repeat what you already said\\n- User is responding to YOUR previous statement` :\\n`- No previous bot responses in this session yet\\n- This is your first chance to speak`}`;\n\n// Build the complete system prompt\nconst systemPrompt = `You are a voice assistant in a Microsoft Teams meeting.\\n\\n## How This Works\\nYour text output is AUTOMATICALLY converted to speech and played in the meeting.\\nDo NOT describe what you'll say - just say it directly.\\n\\n${intentMarkersSection}\\n${chunkContext}\\n${sessionStateSection}\\n\\n## CRITICAL ANTI-REPEAT RULES\\n\\n**YOUR PREVIOUS RESPONSES (DO NOT SAY THESE AGAIN):**\\n${uniqueResponses.map((r, i) => `${i + 1}. \"${r}\"`).join('\\n')}\\n\\n**If you repeat ANY of the above responses, the user will hear the same thing twice. This is a BAD user experience.**\\n${responseGuidance}\\n\\n## Response Rules\\n\\nURGENCY: ${urgency.toUpperCase()} | COMPLETE THOUGHT: ${isComplete ? 'YES' : 'NO'}\\n\\n${urgency === 'wait' || urgency === 'none' ?\\n`⚠️ STAY SILENT - ${urgency === 'wait' ? 'incomplete sentence, wait for more' : 'background conversation'}\\nOutput nothing. This is correct behavior.` :\\n`Respond concisely (1-2 sentences). Your words will be spoken aloud.`}\\n\\n## Tools Available\\n- gmail_agent: Send emails (requires transcript + email_address)\\n- think: Internal reasoning (silent, user won't hear)\\n\\n## Email Workflow\\n1. If user asks to send email but no address: Ask for email address ONCE\\n2. If you already asked: WAIT for them to provide it\\n3. When you have both content and address: Call gmail_agent\\n4. Confirm when done: \\\"Email sent!\\\"\\n${conversationHistory}\\n\\n## Current Input\\nIntent: ${transcript.intent || 'unknown'}\\nSpeaker: ${transcript.speaker || 'unknown'}\\nMessage #${historyRows.length + 1}\\nIs first message this session: ${isFirstMessage ? 'YES' : 'NO'}\\nChunk #${chunkNumber} in current session\\nAccumulated transcript length: ${accumulatedTranscript.length} chars\\nCache used: ${transcript.use_cached_context ? 'YES' : 'NO'}\\n\\nRespond naturally, briefly, and NEVER repeat a previous response verbatim.`;\n\nreturn [{\n  json: {\n    user_input: transcript.transcript,\n    bot_id: transcript.bot_id,\n    is_final: transcript.is_final,\n    intent: transcript.intent,\n    current_state: historyRows[0]?.ai_analysis?.conversation_state || 'IDLE',\n    message_count: historyRows.length + 1,\n    session_id: transcript.bot_id + '_session',\n    received_at: transcript.received_at,\n    response_urgency: urgency,\n    is_complete_thought: isComplete,\n    is_continuation: isContinuation,\n    already_asked_for_email: alreadyAskedForEmail,\n    is_first_message: isFirstMessage,\n    processing_count: processingCount,\n    chunk_number: chunkNumber,\n    accumulated_transcript: accumulatedTranscript,\n    cache_hit: transcript.use_cached_context || false,\n    context_age_ms: transcript.context_age_ms || 0,\n    last_orchestrator_cues: lastOrchestratorCues,\n    pending_actions: pendingActions,\n    system_prompt: systemPrompt,\n    chat_input: transcript.transcript\n  }\n}];"
      },
      "id": "build-context-1",
      "name": "Build Agent Context",
      "type": "n8n-nodes-base.code",
      "position": [
        848,
        480
      ],
      "typeVersion": 2
    },
    {
      "parameters": {
        "promptType": "define",
        "text": "={{ $json.chat_input }}",
        "options": {
          "systemMessage": "={{ $json.system_prompt }}",
          "maxIterations": 5
        }
      },
      "type": "@n8n/n8n-nodes-langchain.agent",
      "typeVersion": 3,
      "position": [
        1024,
        480
      ],
      "id": "6b9b0552-8540-47fa-b65d-d2d46882fc5a",
      "name": "Orchestrator Agent"
    },
    {
      "parameters": {
        "model": "openai/gpt-4o-mini",
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenRouter",
      "typeVersion": 1,
      "position": [
        912,
        720
      ],
      "id": "1dc8c729-f513-4140-94f1-db3ddf723700",
      "name": "OpenRouter Chat Model",
      "credentials": {
        "openRouterApi": {
          "id": "OPPAOWUbmkR2frSd",
          "name": "OpenRouter account"
        }
      }
    },
    {
      "parameters": {
        "description": "Send emails on behalf of the user. Provide the recipient's email address and what to say in the email.",
        "workflowId": {
          "__rl": true,
          "value": "kL0AP3CkRby6OmVb",
          "mode": "id"
        },
        "workflowInputs": {
          "mappingMode": "defineBelow",
          "value": {
            "transcript": "={{ $fromAI('transcript', 'The user request or message content for the email', 'string') }}",
            "email_address": "={{ $fromAI('email_address', 'The recipient email address to send to (REQUIRED)', 'string') }}",
            "context": "={{ {} }}",
            "bot_id": "={{ $('Build Agent Context').first().json.bot_id }}",
            "session_id": "={{ $('Build Agent Context').first().json.session_id }}"
          },
          "schema": [
            {
              "id": "transcript",
              "displayName": "transcript",
              "required": true,
              "defaultMatch": false,
              "canBeUsedToMatch": true,
              "display": true,
              "type": "string",
              "readOnly": false,
              "removed": false
            },
            {
              "id": "email_address",
              "displayName": "email_address",
              "required": true,
              "defaultMatch": false,
              "canBeUsedToMatch": true,
              "display": true,
              "type": "string",
              "readOnly": false,
              "removed": false
            },
            {
              "id": "context",
              "displayName": "context",
              "required": false,
              "defaultMatch": false,
              "canBeUsedToMatch": true,
              "display": true,
              "type": "object",
              "readOnly": false,
              "removed": false
            },
            {
              "id": "bot_id",
              "displayName": "bot_id",
              "required": true,
              "defaultMatch": false,
              "canBeUsedToMatch": true,
              "display": true,
              "type": "string",
              "readOnly": false,
              "removed": false
            },
            {
              "id": "session_id",
              "displayName": "session_id",
              "required": true,
              "defaultMatch": false,
              "canBeUsedToMatch": true,
              "display": true,
              "type": "string",
              "readOnly": false,
              "removed": false
            }
          ]
        }
      },
      "id": "gmail-tool-1",
      "name": "Gmail Agent Tool",
      "type": "@n8n/n8n-nodes-langchain.toolWorkflow",
      "position": [
        1376,
        784
      ],
      "typeVersion": 2.2
    },
    {
      "parameters": {},
      "id": "think-tool-1",
      "name": "Think Tool",
      "type": "@n8n/n8n-nodes-langchain.toolThink",
      "position": [
        1520,
        768
      ],
      "typeVersion": 1.1
    },
    {
      "parameters": {
        "jsCode": "// Build Immutable Log v2.1 - Enhanced with session_state and is_first_message\nconst agent = $('Orchestrator Agent').first().json;\nconst context = $('Build Agent Context').first().json;\nconst classifier = $('Process Transcript').first().json;\n\nlet ttsSuccess = false, sentenceCount = 0;\nlet ttsMessage = agent.output || '';\n\ntry {\n  const sentenceData = $('Split into Sentences').first();\n  if (sentenceData && sentenceData.json) {\n    sentenceCount = sentenceData.json.total_sentences || 1;\n    ttsSuccess = true;\n  }\n} catch (e) { sentenceCount = 1; }\n\ntry {\n  const sendResults = $('Send Sentence Audio').all();\n  if (sendResults && sendResults.length > 0) {\n    ttsSuccess = sendResults.every(r => !r.json.error);\n  }\n} catch (e) {}\n\nlet toolCalls = [];\ntry {\n  if (agent.intermediateSteps) {\n    toolCalls = agent.intermediateSteps.map(step => ({\n      tool: (step.action && step.action.tool) || 'unknown',\n      input: (step.action && step.action.toolInput) || {},\n      output: step.observation || null\n    }));\n  }\n  if (agent.steps && agent.steps.length > 0) {\n    toolCalls = agent.steps.map(step => ({\n      tool: (step.action && step.action.tool) || 'unknown',\n      input: (step.action && step.action.toolInput) || {},\n      output: step.observation || null\n    }));\n  }\n} catch (e) { toolCalls = []; }\n\ntoolCalls.push({\n  tool: 'chunked_tts',\n  input: { message: ttsMessage, sentence_count: sentenceCount },\n  output: ttsSuccess ? 'Sent ' + sentenceCount + ' audio chunks' : 'TTS failed'\n});\n\n// Update static data with orchestrator cues for next iteration\nconst staticData = $getWorkflowStaticData('global');\nif (staticData.botTranscripts && staticData.botTranscripts[context.bot_id]) {\n  // Store the AI output for next iteration's session_state\n  staticData.botTranscripts[context.bot_id].lastOrchestratorCues = agent.output || '';\n  // Track pending actions from tool calls\n  const pendingTools = toolCalls.filter(tc => \n    tc.tool !== 'chunked_tts' && tc.tool !== 'think' && \n    tc.output && tc.output.includes && tc.output.includes('pending')\n  ).map(tc => tc.tool);\n  staticData.botTranscripts[context.bot_id].pendingActions = pendingTools;\n}\n\nreturn {\n  transcript_exact: context.user_input || '',\n  agent_output_raw: agent.output || '',\n  tool_calls: toolCalls,\n  timestamps: {\n    received_at: context.received_at,\n    processed_at: Date.now(),\n    logged_at: new Date().toISOString()\n  },\n  session_id: context.session_id,\n  bot_id: context.bot_id,\n  classifier_route: classifier.route,\n  classifier_intent: classifier.intent,\n  tts_result: {\n    success: ttsSuccess,\n    audio_sent: ttsSuccess,\n    call_count: sentenceCount,\n    chunked: true,\n    source: 'sentence_loop'\n  },\n  workflow_source: 'orchestrator',\n  error_flags: {\n    agent_error: !agent.output,\n    tts_error: !ttsSuccess\n  },\n  // NEW: Pass session state and first message flag to logging sub-workflow\n  session_state: classifier.session_state || {\n    last_orchestrator_cues: '',\n    pending_actions: [],\n    processing_count: 0\n  },\n  is_first_message: classifier.is_first_message || false\n};"
      },
      "id": "log-1",
      "name": "Build Immutable Log",
      "type": "n8n-nodes-base.code",
      "position": [
        2000,
        528
      ],
      "typeVersion": 2
    },
    {
      "parameters": {
        "workflowId": {
          "__rl": true,
          "value": "8LX5tt3SkO8GNuLj",
          "mode": "id"
        },
        "options": {}
      },
      "id": "call-logging-agent",
      "name": "Call Logging Agent",
      "type": "n8n-nodes-base.executeWorkflow",
      "typeVersion": 1.2,
      "position": [
        2208,
        528
      ]
    },
    {
      "parameters": {
        "conditions": {
          "options": {
            "version": 2,
            "leftValue": "",
            "caseSensitive": true,
            "typeValidation": "strict"
          },
          "combinator": "and",
          "conditions": [
            {
              "id": "has-output",
              "operator": {
                "type": "string",
                "operation": "notEmpty"
              },
              "leftValue": "={{ $json.output }}",
              "rightValue": ""
            }
          ]
        },
        "options": {}
      },
      "id": "check-output-if",
      "name": "Check Agent Output",
      "type": "n8n-nodes-base.if",
      "typeVersion": 2.3,
      "position": [
        1392,
        496
      ]
    },
    {
      "parameters": {
        "jsCode": "// SENTENCE-LEVEL TTS CHUNKING\n// Split agent output into sentences for progressive audio delivery\nconst agentOutput = $('Orchestrator Agent').first().json.output || '';\nconst botId = $('Build Agent Context').first().json.bot_id;\n\nif (!agentOutput.trim()) {\n  return [{ json: { sentences: [], bot_id: botId, total_sentences: 0, skip_tts: true } }];\n}\n\n// Split by sentence boundaries\n// Matches: . ! ? followed by space or end of string\n// Preserves punctuation with the sentence\nconst sentencePattern = /[^.!?]*[.!?]+(?:\\s|$)/g;\nlet sentences = agentOutput.match(sentencePattern) || [agentOutput];\n\n// Clean up sentences\nsentences = sentences\n  .map(s => s.trim())\n  .filter(s => s.length > 0);\n\n// If no sentences found (no punctuation), treat as single chunk\nif (sentences.length === 0) {\n  sentences = [agentOutput.trim()];\n}\n\n// Return array of items - one per sentence\nconst items = sentences.map((sentence, index) => ({\n  json: {\n    sentence: sentence,\n    sentence_index: index,\n    total_sentences: sentences.length,\n    bot_id: botId,\n    is_first: index === 0,\n    is_last: index === sentences.length - 1,\n    full_output: agentOutput\n  }\n}));\n\nreturn items;"
      },
      "id": "split-sentences",
      "name": "Split into Sentences",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        912,
        200
      ]
    },
    {
      "parameters": {
        "jsCode": "// PARALLEL TTS GENERATION → SEQUENTIAL RECALL.AI DELIVERY\n// v2: Added bot status check before sending\n\nconst items = $input.all();\nif (!items.length) {\n  return [{ json: { success: false, error: 'No sentences to process' } }];\n}\n\nconst bot_id = items[0].json.bot_id;\nconst voice = items[0].json.voice || 'alloy';\n\nconst OPENAI_API_KEY = 'OPENAI_API_KEY_REDACTED';\nconst RECALL_API_KEY = '4f12c2c033fc1f0fe1e4ca2fcd0aad92b547ff43';\n\n// STEP 0: Check bot status first\nlet botActive = false;\nlet botStatus = 'unknown';\ntry {\n  const statusResponse = await this.helpers.httpRequest({\n    method: 'GET',\n    url: `https://us-west-2.recall.ai/api/v1/bot/${bot_id}/`,\n    headers: {\n      'Authorization': `Token ${RECALL_API_KEY}`\n    },\n    returnFullResponse: false\n  });\n  \n  // Check the last status in status_changes array\n  if (statusResponse.status_changes && statusResponse.status_changes.length > 0) {\n    const lastStatus = statusResponse.status_changes[statusResponse.status_changes.length - 1];\n    botStatus = lastStatus.code;\n    // Active states: in_call_recording, in_call_not_recording\n    botActive = ['in_call_recording', 'in_call_not_recording'].includes(botStatus);\n  }\n} catch (error) {\n  console.log(`Bot status check failed: ${error.message}`);\n  botStatus = 'check_failed';\n  botActive = false;\n}\n\nif (!botActive) {\n  return [{\n    json: {\n      ...items[0].json,\n      tts_summary: {\n        total_sentences: items.length,\n        tts_generated: 0,\n        tts_failed: 0,\n        audio_sent: 0,\n        send_failed: 0,\n        send_errors: [],\n        skipped_reason: `Bot not active (status: ${botStatus})`\n      }\n    }\n  }];\n}\n\n// STEP 1: Generate ALL TTS in parallel\nconst ttsPromises = items.map(async (item, index) => {\n  const sentence = item.json.sentence;\n  const sentenceIndex = item.json.sentence_index ?? index;\n  \n  try {\n    const response = await this.helpers.httpRequest({\n      method: 'POST',\n      url: 'https://api.openai.com/v1/audio/speech',\n      headers: {\n        'Authorization': `Bearer ${OPENAI_API_KEY}`,\n        'Content-Type': 'application/json'\n      },\n      body: JSON.stringify({\n        model: 'tts-1',\n        voice: voice,\n        input: sentence,\n        response_format: 'mp3'\n      }),\n      encoding: 'arraybuffer',\n      returnFullResponse: false\n    });\n    \n    const audio_base64 = Buffer.from(response).toString('base64');\n    \n    return {\n      sentenceIndex,\n      sentence,\n      audio_base64,\n      success: true\n    };\n  } catch (error) {\n    return {\n      sentenceIndex,\n      sentence,\n      error: error.message,\n      success: false\n    };\n  }\n});\n\nconst allAudio = await Promise.all(ttsPromises);\nconst failures = allAudio.filter(a => !a.success);\nconst successfulAudio = allAudio.filter(a => a.success);\nsuccessfulAudio.sort((a, b) => a.sentenceIndex - b.sentenceIndex);\n\n// STEP 2: Send to Recall.ai SEQUENTIALLY\nconst sendResults = [];\nfor (const audio of successfulAudio) {\n  try {\n    await this.helpers.httpRequest({\n      method: 'POST',\n      url: `https://us-west-2.recall.ai/api/v1/bot/${bot_id}/output_audio/`,\n      headers: {\n        'Authorization': `Token ${RECALL_API_KEY}`,\n        'Content-Type': 'application/json'\n      },\n      body: JSON.stringify({\n        kind: 'mp3',\n        b64_data: audio.audio_base64\n      }),\n      returnFullResponse: false\n    });\n    \n    sendResults.push({\n      sentenceIndex: audio.sentenceIndex,\n      sent: true\n    });\n  } catch (error) {\n    sendResults.push({\n      sentenceIndex: audio.sentenceIndex,\n      sent: false,\n      error: error.message\n    });\n  }\n}\n\nreturn [{\n  json: {\n    ...items[0].json,\n    tts_summary: {\n      total_sentences: items.length,\n      tts_generated: successfulAudio.length,\n      tts_failed: failures.length,\n      audio_sent: sendResults.filter(r => r.sent).length,\n      send_failed: sendResults.filter(r => !r.sent).length,\n      send_errors: sendResults.filter(r => !r.sent).map(r => r.error),\n      bot_status: botStatus\n    }\n  }\n}];"
      },
      "id": "parallel-tts-send",
      "name": "Parallel TTS & Send",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        1808,
        384
      ]
    },
    {
      "id": "ultra-fast-prerouter",
      "name": "Ultra-Fast Pre-Router",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        100,
        304
      ],
      "parameters": {
        "mode": "runOnceForAllItems",
        "language": "javaScript",
        "jsCode": "// ============================================================\n// ULTRA-FAST PRE-ROUTER - Sub-10ms Heuristic Classifier\n// ============================================================\n// PURPOSE: Fast-path routing to avoid heavy processing for obvious cases\n// GOAL: <10ms execution using pure heuristics, NO DB, NO API calls\n// ============================================================\n\nconst startTime = Date.now();\n\n// Extract webhook data\nconst body = $input.first().json.body || $input.first().json;\nconst transcript = (body.transcript || '').trim();\nconst bot_id = body.bot_id || 'unknown';\nconst session_id = body.session_id || '';\n\n// ============================================================\n// HEURISTIC ANALYSIS (all sub-millisecond operations)\n// ============================================================\n\n// 1. Empty/whitespace detection\nconst isEmpty = !transcript || transcript.length === 0;\nconst isWhitespaceOnly = /^\\s*$/.test(transcript);\n\n// 2. Word analysis\nconst words = transcript.split(/\\s+/).filter(w => w.length > 0);\nconst wordCount = words.length;\n\n// 3. Punctuation detection (end-of-thought indicators)\nconst hasEndPunctuation = /[.!?]\\s*$/.test(transcript);\nconst hasMidPunctuation = /[.!?,;:]/.test(transcript.slice(0, -1));\nconst punctuationCount = (transcript.match(/[.!?,;:]/g) || []).length;\n\n// 4. Bot name detection (phonetic variations)\n// Matches: \"SYNRG\", \"Synergy\", \"synrgy\", \"synergy bot\", etc.\nconst botNamePattern = /\\b(synr?g[yie]?|synergy)\\s*(bot)?\\b/i;\nconst isAddressingBot = botNamePattern.test(transcript);\n\n// 5. Greeting detection\nconst greetingPattern = /^(h(i|ey|ello)|good\\s*(morning|afternoon|evening)|what'?s\\s*up|yo\\b)/i;\nconst isGreeting = greetingPattern.test(transcript) && wordCount <= 5;\n\n// 6. Question detection\nconst isQuestion = /\\?\\s*$/.test(transcript) || \n                   /^(what|where|when|why|how|who|can|could|would|will|is|are|do|does)\\b/i.test(transcript);\n\n// 7. Request/command detection\nconst requestPattern = /\\b(send|email|help|remind|schedule|book|create|make|please|can you|could you)\\b/i;\nconst hasRequest = requestPattern.test(transcript);\n\n// 8. Filler/noise detection\nconst fillerPattern = /^(um+|uh+|ah+|er+|hmm+|like|so|well|okay|ok)\\s*$/i;\nconst isFillerOnly = fillerPattern.test(transcript);\n\n// 9. Continuation detection (no greeting, mid-sentence start)\nconst startsLowercase = /^[a-z]/.test(transcript);\nconst startsMidThought = startsLowercase && !isGreeting && wordCount > 2;\n\n// ============================================================\n// CONFIDENCE SCORING\n// ============================================================\n\nlet completenessScore = 0;\n\n// Positive signals (thought is complete)\nif (hasEndPunctuation) completenessScore += 0.4;\nif (wordCount >= 7) completenessScore += 0.2;\nif (isQuestion) completenessScore += 0.2;\nif (hasRequest) completenessScore += 0.15;\nif (isAddressingBot) completenessScore += 0.15;\n\n// Negative signals (thought is incomplete)\nif (wordCount < 3) completenessScore -= 0.3;\nif (startsMidThought && !hasEndPunctuation) completenessScore -= 0.2;\nif (transcript.endsWith(',')) completenessScore -= 0.3;\nif (/\\b(and|but|or|so|then|because|if|when|while)\\s*$/i.test(transcript)) completenessScore -= 0.4;\n\n// Clamp to 0-1 range\nconst completeness = Math.max(0, Math.min(1, completenessScore + 0.5));\n\n// ============================================================\n// ROUTING DECISION (Graduated Response Modes)\n// ============================================================\n// Routes:\n//   SILENT       - No action, don't even log heavily\n//   BUFFER       - Accumulate transcript, wait for more\n//   ACKNOWLEDGE  - Quick acknowledgment (\"I hear you\")\n//   QUICK_REPLY  - Simple cached/template response\n//   FULL_PROCESS - Full agent processing required\n// ============================================================\n\nlet preRoute = 'BUFFER'; // Default: wait for more\nlet routeReason = '';\nlet urgency = 'low';\n\n// Decision tree (order matters - most specific first)\n\nif (isEmpty || isWhitespaceOnly) {\n  preRoute = 'SILENT';\n  routeReason = 'empty_transcript';\n  urgency = 'none';\n}\nelse if (isFillerOnly) {\n  preRoute = 'SILENT';\n  routeReason = 'filler_noise';\n  urgency = 'none';\n}\nelse if (wordCount === 1 && !isAddressingBot && !isGreeting) {\n  preRoute = 'SILENT';\n  routeReason = 'single_word_noise';\n  urgency = 'none';\n}\nelse if (isAddressingBot && hasRequest) {\n  // Bot addressed + clear request = immediate processing\n  preRoute = 'FULL_PROCESS';\n  routeReason = 'bot_addressed_with_request';\n  urgency = 'immediate';\n}\nelse if (isAddressingBot && (isQuestion || isGreeting)) {\n  // Bot addressed + question or greeting = process\n  preRoute = 'FULL_PROCESS';\n  routeReason = 'bot_addressed_directly';\n  urgency = 'high';\n}\nelse if (isGreeting && wordCount <= 3) {\n  // Simple greeting - quick template response\n  preRoute = 'QUICK_REPLY';\n  routeReason = 'simple_greeting';\n  urgency = 'standard';\n}\nelse if (hasRequest && hasEndPunctuation) {\n  // Clear request with complete thought\n  preRoute = 'FULL_PROCESS';\n  routeReason = 'complete_request';\n  urgency = 'high';\n}\nelse if (completeness >= 0.7 && wordCount >= 5) {\n  // High confidence complete thought\n  preRoute = 'FULL_PROCESS';\n  routeReason = 'complete_thought';\n  urgency = 'standard';\n}\nelse if (completeness >= 0.5 && wordCount >= 7) {\n  // Moderate confidence but enough content\n  preRoute = 'FULL_PROCESS';\n  routeReason = 'sufficient_content';\n  urgency = 'standard';\n}\nelse if (isAddressingBot) {\n  // Bot addressed but unclear intent - acknowledge\n  preRoute = 'ACKNOWLEDGE';\n  routeReason = 'bot_addressed_unclear';\n  urgency = 'standard';\n}\nelse if (wordCount >= 3 && wordCount < 6 && !hasEndPunctuation) {\n  // Short phrase, no punctuation - buffer and wait\n  preRoute = 'BUFFER';\n  routeReason = 'incomplete_phrase';\n  urgency = 'low';\n}\nelse if (wordCount < 3) {\n  preRoute = 'BUFFER';\n  routeReason = 'too_short';\n  urgency = 'low';\n}\n\n// ============================================================\n// STATIC DATA: Session Tracking\n// ============================================================\nconst staticData = $getWorkflowStaticData('global');\nstaticData.preRouterStats = staticData.preRouterStats || {};\nconst stats = staticData.preRouterStats;\n\n// Track routing decisions for learning\nstats[preRoute] = (stats[preRoute] || 0) + 1;\nstats.totalCalls = (stats.totalCalls || 0) + 1;\n\n// Session tracking for greeting detection\nstaticData.sessionInfo = staticData.sessionInfo || {};\nconst sessionKey = `${bot_id}_${session_id}`;\nconst isFirstMessage = !staticData.sessionInfo[sessionKey];\nif (isFirstMessage) {\n  staticData.sessionInfo[sessionKey] = { firstSeen: Date.now(), messageCount: 0 };\n}\nstaticData.sessionInfo[sessionKey].messageCount++;\nstaticData.sessionInfo[sessionKey].lastSeen = Date.now();\n\n// ============================================================\n// OUTPUT\n// ============================================================\nconst executionTime = Date.now() - startTime;\n\nreturn [{\n  json: {\n    // Pass through original data\n    ...body,\n    \n    // Pre-router classification\n    pre_route: preRoute,\n    route_reason: routeReason,\n    urgency: urgency,\n    \n    // Heuristic analysis results\n    heuristics: {\n      word_count: wordCount,\n      has_end_punctuation: hasEndPunctuation,\n      is_addressing_bot: isAddressingBot,\n      is_greeting: isGreeting,\n      is_question: isQuestion,\n      has_request: hasRequest,\n      is_filler: isFillerOnly,\n      completeness_score: Math.round(completeness * 100) / 100,\n      is_first_message: isFirstMessage\n    },\n    \n    // Performance tracking\n    pre_router_ms: executionTime,\n    \n    // Intent markers for feedback loop\n    intent_markers: {\n      near_end_of_thought: completeness >= 0.6,\n      request_detected: hasRequest,\n      bot_addressed: isAddressingBot,\n      greeting_detected: isGreeting,\n      question_detected: isQuestion\n    }\n  }\n}];"
      }
    },
    {
      "id": "pre-route-switch",
      "name": "Pre-Route Switch",
      "type": "n8n-nodes-base.switch",
      "typeVersion": 3,
      "position": [
        208,
        304
      ],
      "parameters": {
        "rules": {
          "values": [
            {
              "conditions": {
                "options": {
                  "version": 2,
                  "leftValue": "",
                  "caseSensitive": true,
                  "typeValidation": "strict"
                },
                "combinator": "and",
                "conditions": [
                  {
                    "id": "rule-silent",
                    "operator": {
                      "type": "string",
                      "operation": "equals"
                    },
                    "leftValue": "={{ $json.pre_route }}",
                    "rightValue": "SILENT"
                  }
                ]
              },
              "renameOutput": true,
              "outputKey": "SILENT"
            },
            {
              "conditions": {
                "options": {
                  "version": 2,
                  "leftValue": "",
                  "caseSensitive": true,
                  "typeValidation": "strict"
                },
                "combinator": "and",
                "conditions": [
                  {
                    "id": "rule-buffer",
                    "operator": {
                      "type": "string",
                      "operation": "equals"
                    },
                    "leftValue": "={{ $json.pre_route }}",
                    "rightValue": "BUFFER"
                  }
                ]
              },
              "renameOutput": true,
              "outputKey": "BUFFER"
            },
            {
              "conditions": {
                "options": {
                  "version": 2,
                  "leftValue": "",
                  "caseSensitive": true,
                  "typeValidation": "strict"
                },
                "combinator": "and",
                "conditions": [
                  {
                    "id": "rule-ack",
                    "operator": {
                      "type": "string",
                      "operation": "equals"
                    },
                    "leftValue": "={{ $json.pre_route }}",
                    "rightValue": "ACKNOWLEDGE"
                  }
                ]
              },
              "renameOutput": true,
              "outputKey": "ACKNOWLEDGE"
            },
            {
              "conditions": {
                "options": {
                  "version": 2,
                  "leftValue": "",
                  "caseSensitive": true,
                  "typeValidation": "strict"
                },
                "combinator": "and",
                "conditions": [
                  {
                    "id": "rule-quick",
                    "operator": {
                      "type": "string",
                      "operation": "equals"
                    },
                    "leftValue": "={{ $json.pre_route }}",
                    "rightValue": "QUICK_REPLY"
                  }
                ]
              },
              "renameOutput": true,
              "outputKey": "QUICK_REPLY"
            },
            {
              "conditions": {
                "options": {
                  "version": 2,
                  "leftValue": "",
                  "caseSensitive": true,
                  "typeValidation": "strict"
                },
                "combinator": "and",
                "conditions": [
                  {
                    "id": "rule-full",
                    "operator": {
                      "type": "string",
                      "operation": "equals"
                    },
                    "leftValue": "={{ $json.pre_route }}",
                    "rightValue": "FULL_PROCESS"
                  }
                ]
              },
              "renameOutput": true,
              "outputKey": "FULL_PROCESS"
            }
          ]
        },
        "options": {
          "fallbackOutput": "extra"
        }
      }
    },
    {
      "id": "acknowledge-handler",
      "name": "Quick Acknowledge",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        672,
        64
      ],
      "parameters": {
        "mode": "runOnceForAllItems",
        "language": "javaScript",
        "jsCode": "// QUICK ACKNOWLEDGE - Fast response for unclear bot addressing\nconst input = $input.first().json;\nconst ackOptions = [\"I'm listening...\", \"Go ahead...\", \"Yes?\", \"I hear you...\"];\nconst acknowledgment = ackOptions[Date.now() % ackOptions.length];\n\nreturn [{\n  json: {\n    ...input,\n    response_type: 'acknowledge',\n    response_text: acknowledgment,\n    should_speak: true,\n    route_taken: 'ACKNOWLEDGE'\n  }\n}];"
      }
    },
    {
      "id": "quick-reply-handler",
      "name": "Quick Reply",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        672,
        176
      ],
      "parameters": {
        "mode": "runOnceForAllItems",
        "language": "javaScript",
        "jsCode": "// QUICK REPLY - Template response for simple greetings\nconst input = $input.first().json;\nconst heuristics = input.heuristics || {};\nconst staticData = $getWorkflowStaticData('global');\nconst sessionKey = `${input.bot_id}_${input.session_id || ''}`;\n\nlet response = '';\nif (heuristics.is_greeting) {\n  const greetings = [\"Hello! How can I help?\", \"Hi there! What can I do for you?\", \"Hey! I'm ready to help.\"];\n  response = greetings[Date.now() % greetings.length];\n  staticData.greetingsSent = staticData.greetingsSent || {};\n  staticData.greetingsSent[sessionKey] = Date.now();\n} else {\n  response = \"I'm here. How can I help?\";\n}\n\nreturn [{\n  json: {\n    ...input,\n    response_type: 'quick_reply',\n    response_text: response,\n    should_speak: true,\n    route_taken: 'QUICK_REPLY'\n  }\n}];"
      }
    }
  ],
  "connections": {
    "Process Transcript": {
      "main": [
        [
          {
            "node": "Route Switch",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Route Switch": {
      "main": [
        [
          {
            "node": "Log Silent Transcript",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Wait Log Only",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Log Listen Transcript",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Load Bot State",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Wait Log Only": {
      "main": [
        [
          {
            "node": "Log Wait Transcript",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Build Agent Context": {
      "main": [
        [
          {
            "node": "Orchestrator Agent",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "OpenRouter Chat Model": {
      "ai_languageModel": [
        [
          {
            "node": "Orchestrator Agent",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "Gmail Agent Tool": {
      "ai_tool": [
        [
          {
            "node": "Orchestrator Agent",
            "type": "ai_tool",
            "index": 0
          }
        ]
      ]
    },
    "Think Tool": {
      "ai_tool": [
        [
          {
            "node": "Orchestrator Agent",
            "type": "ai_tool",
            "index": 0
          }
        ]
      ]
    },
    "Build Immutable Log": {
      "main": [
        [
          {
            "node": "Call Logging Agent",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Load Bot State": {
      "main": [
        [
          {
            "node": "Build Agent Context",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Orchestrator Agent": {
      "main": [
        [
          {
            "node": "Check Agent Output",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Check Agent Output": {
      "main": [
        [
          {
            "node": "Split into Sentences",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Build Immutable Log",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Split into Sentences": {
      "main": [
        [
          {
            "node": "Parallel TTS & Send",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Parallel TTS & Send": {
      "main": [
        [
          {
            "node": "Build Immutable Log",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Webhook": {
      "main": [
        [
          {
            "node": "Ultra-Fast Pre-Router",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Ultra-Fast Pre-Router": {
      "main": [
        [
          {
            "node": "Pre-Route Switch",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Pre-Route Switch": {
      "0": [
        [
          {
            "node": "Log Silent Transcript",
            "type": "0",
            "index": 0
          }
        ]
      ],
      "1": [
        [
          {
            "node": "Wait Log Only",
            "type": "1",
            "index": 0
          }
        ]
      ],
      "4": [
        [
          {
            "node": "Process Transcript",
            "type": "4",
            "index": 0
          }
        ]
      ],
      "main": [
        [],
        [],
        [
          {
            "node": "Quick Acknowledge",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Quick Reply",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Quick Acknowledge": {
      "main": [
        [
          {
            "node": "Split into Sentences",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Quick Reply": {
      "main": [
        [
          {
            "node": "Split into Sentences",
            "type": "main",
            "index": 0
          }
        ]
      ]
    }
  },
  "settings": {
    "executionOrder": "v1",
    "callerPolicy": "workflowsFromSameOwner",
    "availableInMCP": false
  },
  "staticData": {
    "global": {
      "botTranscripts": {
        "a1ccaacd-0a69-4e34-adae-c6e9c49306e0": {
          "lastProcessedTranscript": "can you help me send an email synerg",
          "lastProcessedTime": 1767155893875,
          "pendingWords": [],
          "processingLock": false
        },
        "807b681e-6629-4dea-9f20-8e0315da48c9": {
          "lastProcessedTranscript": "",
          "lastProcessedTime": 0,
          "processingCount": 0
        }
      }
    }
  },
  "meta": {
    "templateCredsSetupCompleted": true
  },
  "pinData": {},
  "versionId": "59850685-126a-44a8-8eb2-5cd130fb63d3",
  "activeVersionId": "59850685-126a-44a8-8eb2-5cd130fb63d3",
  "versionCounter": 362,
  "triggerCount": 1,
  "shared": [
    {
      "updatedAt": "2025-12-27T04:48:10.419Z",
      "createdAt": "2025-12-27T04:48:10.419Z",
      "role": "workflow:owner",
      "workflowId": "d3CxEaYk5mkC8sLo",
      "projectId": "vaRklvnINMqrVVkS",
      "project": {
        "updatedAt": "2025-05-03T20:14:26.988Z",
        "createdAt": "2025-05-03T20:14:24.356Z",
        "id": "vaRklvnINMqrVVkS",
        "name": "Jay Connor <jayconnor@exesyndrome.com>",
        "type": "personal",
        "icon": null,
        "description": null,
        "creatorId": "cd6f3efb-1d17-4b28-b2dc-bb38f830be30",
        "projectRelations": [
          {
            "updatedAt": "2025-05-03T20:14:24.357Z",
            "createdAt": "2025-05-03T20:14:24.357Z",
            "userId": "cd6f3efb-1d17-4b28-b2dc-bb38f830be30",
            "projectId": "vaRklvnINMqrVVkS",
            "user": {
              "updatedAt": "2026-01-09T18:09:48.000Z",
              "createdAt": "2025-05-03T20:14:22.867Z",
              "id": "cd6f3efb-1d17-4b28-b2dc-bb38f830be30",
              "email": "jayconnor@exesyndrome.com",
              "firstName": "Jay",
              "lastName": "Connor",
              "personalizationAnswers": null,
              "settings": {
                "userActivated": true,
                "easyAIWorkflowOnboarded": true,
                "firstSuccessfulWorkflowId": "6ALGaDd2bXw27jRn",
                "userActivatedAt": 1747420903813,
                "npsSurvey": {
                  "responded": true,
                  "lastShownAt": 1765406705766
                }
              },
              "disabled": false,
              "mfaEnabled": false,
              "lastActiveAt": "2026-01-09",
              "isPending": false
            }
          }
        ]
      }
    }
  ],
  "tags": [],
  "activeVersion": {
    "updatedAt": "2026-01-10T00:46:18.230Z",
    "createdAt": "2026-01-10T00:46:18.230Z",
    "versionId": "59850685-126a-44a8-8eb2-5cd130fb63d3",
    "workflowId": "d3CxEaYk5mkC8sLo",
    "nodes": [
      {
        "parameters": {
          "httpMethod": "POST",
          "path": "voice-bot-v3",
          "responseMode": "onReceived",
          "options": {}
        },
        "id": "webhook-1",
        "name": "Webhook",
        "type": "n8n-nodes-base.webhook",
        "position": [
          0,
          304
        ],
        "webhookId": "voice-bot-v3",
        "typeVersion": 2.1
      },
      {
        "parameters": {
          "mode": "runOnceForEachItem",
          "jsCode": "// CONSOLIDATED: Parse + Extract + Classify + Response Timing + DEDUPLICATION v4\n// ENHANCED: Added Streaming Context Protocol - caches session context to avoid redundant DB loads\nconst item = $input.item.json;\nconst body = item.body || {};\nconst data = body.data || {};\nconst inner = data.data || {};\nconst words = inner.words || [];\nconst participant = inner.participant || {};\nconst bot = data.bot || {};\n\n// Early exit if no words\nif (!Array.isArray(words) || words.length === 0) {\n  return {\n    json: {\n      route: 'NO_TRANSCRIPT',\n      event_type: body.event || 'unknown',\n      bot_id: bot.id || 'unknown',\n      transcript: '',\n      is_final: false,\n      speaker: 'unknown',\n      speaker_id: null,\n      is_host: false,\n      received_at: Date.now(),\n      intent: 'no_content',\n      should_respond: false,\n      is_addressing_bot: false,\n      is_first_message: false,\n      response_timing: { is_complete_thought: false, response_urgency: 'none' },\n      session_state: { last_orchestrator_cues: '', pending_actions: [], processing_count: 0 },\n      classified_at: new Date().toISOString(),\n      dedup: { is_duplicate: false, reason: 'no_words' },\n      // Streaming Context Protocol fields\n      use_cached_context: false,\n      cached_history: [],\n      accumulated_transcript: '',\n      context_age_ms: 0,\n      chunk_number: 0\n    }\n  };\n}\n\nconst transcript = words.map(w => w.text).join(' ').trim();\nconst speaker = participant.name || 'unknown';\nconst bot_id = bot.id || 'unknown';\n\n// === SESSION STATE & DEDUPLICATION v4 + STREAMING CONTEXT PROTOCOL ===\nconst staticData = $getWorkflowStaticData('global');\nconst now = Date.now();\n\nif (!staticData.botTranscripts) staticData.botTranscripts = {};\nif (!staticData.botTranscripts[bot_id]) {\n  staticData.botTranscripts[bot_id] = {\n    // Existing fields\n    lastProcessedTranscript: '',\n    lastProcessedTime: 0,\n    processingCount: 0,\n    sessionStartTime: now,\n    lastOrchestratorCues: '',\n    pendingActions: [],\n\n    // NEW: Streaming Context Protocol fields\n    cachedHistory: [],              // Cached DB rows\n    cachedHistoryTime: 0,           // When cache was populated\n    accumulatedTranscript: '',      // All chunks this session\n    chunkNumber: 0,                 // Current chunk count\n    lastRouteDecision: '',          // Track route changes\n    contextValid: false             // Whether cache is usable\n  };\n}\n\nconst botState = staticData.botTranscripts[bot_id];\nconst lastTranscript = botState.lastProcessedTranscript;\nconst timeSinceLastProcess = now - botState.lastProcessedTime;\n\n// Increment chunk number\nbotState.chunkNumber++;\nconst currentChunkNumber = botState.chunkNumber;\n\n// First message detection (no prior processing OR > 5 min inactive)\nconst isFirstMessage = botState.processingCount === 0 || timeSinceLastProcess > 300000;\nif (isFirstMessage && timeSinceLastProcess > 300000) {\n  // Session reset - invalidate cache\n  botState.sessionStartTime = now;\n  botState.processingCount = 0;\n  botState.lastOrchestratorCues = '';\n  botState.pendingActions = [];\n  botState.cachedHistory = [];\n  botState.cachedHistoryTime = 0;\n  botState.accumulatedTranscript = '';\n  botState.chunkNumber = 1;\n  botState.lastRouteDecision = '';\n  botState.contextValid = false;\n}\n\n// Deduplication\nlet isDuplicate = false, isExtension = false, dedupReason = 'new_content';\nif (lastTranscript && timeSinceLastProcess < 15000) {\n  const currentLower = transcript.toLowerCase().trim();\n  const lastLower = lastTranscript.toLowerCase().trim();\n  if (currentLower === lastLower) {\n    isDuplicate = true;\n    dedupReason = 'exact_duplicate';\n  } else if (currentLower.startsWith(lastLower) || lastLower.startsWith(currentLower)) {\n    isExtension = true;\n    dedupReason = currentLower.startsWith(lastLower) ? 'extension_of_previous' : 'subset_of_previous';\n  }\n}\n\n// === RESPONSE TIMING ===\nconst hasEndPunctuation = /[.!?]$/.test(transcript);\nconst wordCount = words.length;\nlet speakingDurationMs = 0;\nif (words.length >= 2) {\n  const f = words[0], l = words[words.length - 1];\n  if (f.start_timestamp?.relative && l.end_timestamp?.relative) {\n    speakingDurationMs = (l.end_timestamp.relative - f.start_timestamp.relative) * 1000;\n  }\n}\n\nconst lowerTranscript = transcript.toLowerCase();\nconst isFromHuman = !['bot', 'assistant'].includes(speaker.toLowerCase());\n\n// PHONETIC bot name detection\nconst botPatterns = [\n  /\\b(synergy|synrg)\\s*bot\\b/i, /\\bsynergy\\b/i, /\\bsynrg\\b/i,\n  /\\bsin\\s*urge\\s*y?\\b/i, /\\bsin\\s*ergy\\b/i, /\\bcin\\s*ergy\\b/i, /\\bsen\\s*ergy\\b/i,\n  /\\bhey\\s+(synergy|synrg|sin\\s*ergy)\\b/i,\n  /\\b(bot|assistant|ai|hey\\s*bot|hello\\s*bot|voice\\s*bot)\\b/i\n];\nconst isAddressingBot = botPatterns.some(p => p.test(lowerTranscript));\n\nconst emailPatterns = /send\\s*(an\\s*)?email|email\\s*to|compose\\s*email|write\\s*(an\\s*)?email/i;\nconst questionPatterns = /\\?$|what|how|when|where|why|can you|could you|tell me|explain/i;\nconst greetingPatterns = /^(hi|hello|hey|good morning|good afternoon|good evening)/i;\nconst commandPatterns = /please|help|need|want|could you|can you|would you/i;\n\n// Complete thought detection (voice-friendly, no punctuation required)\nlet isCompleteThought = false, responseUrgency = 'none';\nif (hasEndPunctuation && wordCount >= 4) {\n  isCompleteThought = true; responseUrgency = 'standard';\n} else if (wordCount >= 10) {\n  isCompleteThought = true; responseUrgency = 'standard';\n} else if (wordCount >= 5 && isAddressingBot) {\n  isCompleteThought = true; responseUrgency = 'immediate';\n} else if (wordCount >= 5 && (emailPatterns.test(lowerTranscript) || commandPatterns.test(lowerTranscript))) {\n  isCompleteThought = true; responseUrgency = 'standard';\n} else if (wordCount < 4) {\n  isCompleteThought = false; responseUrgency = 'wait';\n}\n\nif (isFirstMessage && greetingPatterns.test(lowerTranscript) && wordCount >= 2) {\n  isCompleteThought = true; responseUrgency = 'immediate';\n}\n\nlet route = 'SILENT', intent = 'no_content', shouldRespond = false;\nconst isFinal = isCompleteThought;\n\nif (isDuplicate) {\n  route = 'SILENT'; intent = 'duplicate_skipped';\n} else if (isExtension) {\n  route = 'WAIT_LOG'; intent = 'partial_extension';\n} else if (isFromHuman && isCompleteThought) {\n  const requiresResponse = isAddressingBot ||\n    emailPatterns.test(lowerTranscript) ||\n    (questionPatterns.test(lowerTranscript) && commandPatterns.test(lowerTranscript)) ||\n    (greetingPatterns.test(lowerTranscript) && isFirstMessage);\n\n  if (requiresResponse) {\n    route = 'PROCESS'; shouldRespond = true;\n    intent = emailPatterns.test(lowerTranscript) ? 'email_request' :\n             (greetingPatterns.test(lowerTranscript) && isFirstMessage) ? 'first_greeting' :\n             questionPatterns.test(lowerTranscript) ? 'question' :\n             greetingPatterns.test(lowerTranscript) ? 'greeting' :\n             isAddressingBot ? 'addressing_bot' : 'command';\n    botState.lastProcessedTranscript = transcript;\n    botState.lastProcessedTime = now;\n    botState.processingCount++;\n  } else {\n    route = 'LISTEN'; intent = 'general_speech';\n  }\n} else if (!isCompleteThought && transcript.length > 0) {\n  route = 'WAIT_LOG'; intent = 'partial_transcript';\n}\n\n// === STREAMING CONTEXT PROTOCOL: Cache Management ===\n\n// Accumulate transcript chunks\nif (!isFirstMessage) {\n  botState.accumulatedTranscript += (botState.accumulatedTranscript ? ' ' : '') + transcript;\n} else {\n  botState.accumulatedTranscript = transcript;\n}\n\n// Calculate context age\nconst contextAge = botState.cachedHistoryTime > 0 ? now - botState.cachedHistoryTime : 0;\n\n// Cache invalidation conditions\nconst CACHE_MAX_AGE_MS = 30000; // 30 seconds\nconst cacheIsTooOld = contextAge > CACHE_MAX_AGE_MS;\nconst routeChangedToProcess = route === 'PROCESS' && botState.lastRouteDecision !== 'PROCESS';\nconst shouldInvalidateCache = isFirstMessage || cacheIsTooOld || routeChangedToProcess;\n\n// Determine if we should use cached context or load fresh from DB\nlet useCachedContext = false;\nlet cachedHistory = [];\n\nif (!shouldInvalidateCache && botState.contextValid && botState.cachedHistory.length > 0) {\n  // Cache is valid and fresh - use it\n  useCachedContext = true;\n  cachedHistory = botState.cachedHistory;\n} else {\n  // Cache is invalid - downstream should load fresh from DB\n  useCachedContext = false;\n  cachedHistory = [];\n  botState.contextValid = false; // Mark cache as needing refresh\n}\n\n// Update last route decision\nbotState.lastRouteDecision = route;\n\nreturn {\n  json: {\n    bot_id, transcript, is_final: isFinal, speaker,\n    speaker_id: participant.id || null, is_host: participant.is_host || false,\n    received_at: Date.now(), event_type: body.event || 'unknown',\n    route, intent, should_respond: shouldRespond,\n    is_addressing_bot: isAddressingBot, is_first_message: isFirstMessage,\n    response_timing: { is_complete_thought: isCompleteThought, has_end_punctuation: hasEndPunctuation, word_count: wordCount, speaking_duration_ms: speakingDurationMs, response_urgency: responseUrgency },\n    session_state: { last_orchestrator_cues: botState.lastOrchestratorCues, pending_actions: botState.pendingActions, processing_count: botState.processingCount, session_start_time: botState.sessionStartTime },\n    dedup: { is_duplicate: isDuplicate, is_extension: isExtension, reason: dedupReason, last_processed: lastTranscript, time_since_last_ms: timeSinceLastProcess, processing_count: botState.processingCount },\n    classified_at: new Date().toISOString(),\n\n    // NEW: Streaming Context Protocol output fields\n    use_cached_context: useCachedContext,\n    cached_history: cachedHistory,\n    accumulated_transcript: botState.accumulatedTranscript,\n    context_age_ms: contextAge,\n    chunk_number: currentChunkNumber,\n    cache_invalidation_reason: shouldInvalidateCache ? (\n      isFirstMessage ? 'first_message' :\n      cacheIsTooOld ? 'cache_expired' :\n      routeChangedToProcess ? 'route_changed_to_process' :\n      'unknown'\n    ) : 'cache_valid'\n  }\n};"
        },
        "id": "process-transcript",
        "name": "Process Transcript",
        "type": "n8n-nodes-base.code",
        "position": [
          432,
          496
        ],
        "typeVersion": 2
      },
      {
        "parameters": {
          "rules": {
            "values": [
              {
                "conditions": {
                  "options": {
                    "version": 2,
                    "leftValue": "",
                    "caseSensitive": true,
                    "typeValidation": "strict"
                  },
                  "combinator": "and",
                  "conditions": [
                    {
                      "id": "rule-silent",
                      "operator": {
                        "type": "string",
                        "operation": "equals"
                      },
                      "leftValue": "={{ $json.route }}",
                      "rightValue": "SILENT"
                    }
                  ]
                },
                "renameOutput": true,
                "outputKey": "SILENT"
              },
              {
                "conditions": {
                  "options": {
                    "version": 2,
                    "leftValue": "",
                    "caseSensitive": true,
                    "typeValidation": "strict"
                  },
                  "combinator": "and",
                  "conditions": [
                    {
                      "id": "rule-wait",
                      "operator": {
                        "type": "string",
                        "operation": "equals"
                      },
                      "leftValue": "={{ $json.route }}",
                      "rightValue": "WAIT_LOG"
                    }
                  ]
                },
                "renameOutput": true,
                "outputKey": "WAIT_LOG"
              },
              {
                "conditions": {
                  "options": {
                    "version": 2,
                    "leftValue": "",
                    "caseSensitive": true,
                    "typeValidation": "strict"
                  },
                  "combinator": "and",
                  "conditions": [
                    {
                      "id": "rule-listen",
                      "operator": {
                        "type": "string",
                        "operation": "equals"
                      },
                      "leftValue": "={{ $json.route }}",
                      "rightValue": "LISTEN"
                    }
                  ]
                },
                "renameOutput": true,
                "outputKey": "LISTEN"
              },
              {
                "conditions": {
                  "options": {
                    "version": 2,
                    "leftValue": "",
                    "caseSensitive": true,
                    "typeValidation": "strict"
                  },
                  "combinator": "and",
                  "conditions": [
                    {
                      "id": "rule-process",
                      "operator": {
                        "type": "string",
                        "operation": "equals"
                      },
                      "leftValue": "={{ $json.route }}",
                      "rightValue": "PROCESS"
                    }
                  ]
                },
                "renameOutput": true,
                "outputKey": "PROCESS"
              },
              {
                "conditions": {
                  "options": {
                    "version": 2,
                    "leftValue": "",
                    "caseSensitive": true,
                    "typeValidation": "strict"
                  },
                  "combinator": "and",
                  "conditions": [
                    {
                      "id": "rule-no-transcript",
                      "operator": {
                        "type": "string",
                        "operation": "equals"
                      },
                      "leftValue": "={{ $json.route }}",
                      "rightValue": "NO_TRANSCRIPT"
                    }
                  ]
                },
                "renameOutput": true,
                "outputKey": "NO_TRANSCRIPT"
              }
            ]
          },
          "options": {
            "fallbackOutput": "none"
          }
        },
        "id": "route-switch",
        "name": "Route Switch",
        "type": "n8n-nodes-base.switch",
        "typeVersion": 3.2,
        "position": [
          432,
          288
        ]
      },
      {
        "parameters": {
          "operation": "executeQuery",
          "query": "=INSERT INTO transcript_log (bot_id, transcript, speaker, route, intent, is_final, created_at) VALUES ('{{ $json.bot_id }}', '{{ $json.transcript }}', '{{ $json.speaker }}', '{{ $json.route }}', '{{ $json.intent }}', {{ $json.is_final }}, NOW()) RETURNING id",
          "options": {}
        },
        "id": "log-silent-transcript",
        "name": "Log Silent Transcript",
        "type": "n8n-nodes-base.postgres",
        "position": [
          672,
          -80
        ],
        "typeVersion": 2.6,
        "credentials": {
          "postgres": {
            "id": "NI3jbq1U8xPst3j3",
            "name": "MICROSOFT TEAMS AGENT DATTABASE"
          }
        }
      },
      {
        "parameters": {
          "mode": "runOnceForEachItem",
          "jsCode": "const input = $input.item.json;\nreturn {\n  json: {\n    action: 'wait_log',\n    bot_id: input.bot_id,\n    transcript: input.transcript,\n    speaker: input.speaker,\n    intent: input.intent,\n    route: input.route,\n    is_final: input.is_final,\n    logged_at: new Date().toISOString(),\n    message: 'Partial transcript - logged without response'\n  }\n};"
        },
        "id": "wait-log",
        "name": "Wait Log Only",
        "type": "n8n-nodes-base.code",
        "typeVersion": 2,
        "position": [
          672,
          160
        ]
      },
      {
        "parameters": {
          "operation": "executeQuery",
          "query": "=INSERT INTO transcript_log (bot_id, transcript, speaker, route, intent, is_final, created_at) VALUES ('{{ $json.bot_id }}', '{{ $json.transcript }}', '{{ $json.speaker }}', '{{ $json.route }}', '{{ $json.intent }}', {{ $json.is_final }}, NOW()) RETURNING id",
          "options": {}
        },
        "id": "log-wait-transcript",
        "name": "Log Wait Transcript",
        "type": "n8n-nodes-base.postgres",
        "position": [
          880,
          160
        ],
        "typeVersion": 2.6,
        "credentials": {
          "postgres": {
            "id": "NI3jbq1U8xPst3j3",
            "name": "MICROSOFT TEAMS AGENT DATTABASE"
          }
        }
      },
      {
        "parameters": {
          "operation": "executeQuery",
          "query": "=INSERT INTO transcript_log (bot_id, transcript, speaker, route, intent, is_final, created_at) VALUES ('{{ $json.bot_id }}', '{{ $json.transcript }}', '{{ $json.speaker }}', '{{ $json.route }}', '{{ $json.intent }}', {{ $json.is_final }}, NOW()) RETURNING id",
          "options": {}
        },
        "id": "listen-log",
        "name": "Log Listen Transcript",
        "type": "n8n-nodes-base.postgres",
        "typeVersion": 2.6,
        "position": [
          672,
          320
        ],
        "credentials": {
          "postgres": {
            "id": "NI3jbq1U8xPst3j3",
            "name": "MICROSOFT TEAMS AGENT DATTABASE"
          }
        }
      },
      {
        "parameters": {
          "operation": "executeQuery",
          "query": "=SELECT transcript_exact, agent_output_raw, tool_calls, classifier_intent, logged_at\nFROM interaction_logs \nWHERE bot_id = '{{ $json.bot_id }}' \nORDER BY logged_at DESC \nLIMIT 4",
          "options": {}
        },
        "id": "load-state-1",
        "name": "Load Bot State",
        "type": "n8n-nodes-base.postgres",
        "position": [
          672,
          496
        ],
        "typeVersion": 2.6,
        "alwaysOutputData": true,
        "credentials": {
          "postgres": {
            "id": "NI3jbq1U8xPst3j3",
            "name": "MICROSOFT TEAMS AGENT DATTABASE"
          }
        },
        "onError": "continueRegularOutput"
      },
      {
        "parameters": {
          "jsCode": "// BUILD AGENT CONTEXT - v5 with Streaming Context Protocol + Cache Integration\nconst transcript = $('Process Transcript').first().json;\n\n// === STREAMING CONTEXT PROTOCOL: CACHE-AWARE HISTORY LOADING ===\nlet historyRows = [];\nconst staticData = $getWorkflowStaticData('global');\n\nif (transcript.use_cached_context && transcript.cached_history && transcript.cached_history.length > 0) {\n  // CACHE HIT: Use pre-loaded history from Process Transcript\n  historyRows = transcript.cached_history;\n  console.log(`✓ Cache HIT: Using ${historyRows.length} cached rows (age: ${transcript.context_age_ms}ms, chunk ${transcript.chunk_number})`);\n} else {\n  // CACHE MISS: Load from database\n  try {\n    historyRows = $('Load Bot State').all().map(item => item.json);\n    console.log(`✗ Cache MISS: Loaded ${historyRows.length} rows from DB (chunk ${transcript.chunk_number || 1})`);\n    \n    // POPULATE CACHE for next chunk\n    if (staticData.botTranscripts && staticData.botTranscripts[transcript.bot_id]) {\n      const botState = staticData.botTranscripts[transcript.bot_id];\n      botState.cachedHistory = historyRows;\n      botState.cachedHistoryTime = Date.now();\n      botState.contextValid = true;\n      console.log(`→ Cache populated for bot ${transcript.bot_id}`);\n    }\n  } catch (e) {\n    console.error('Failed to load history:', e.message);\n    historyRows = [];\n  }\n}\n\n// === CHUNK CONTEXT AWARENESS ===\nconst chunkNumber = transcript.chunk_number || 1;\nconst accumulatedTranscript = transcript.accumulated_transcript || transcript.transcript;\nconst isFirstChunk = chunkNumber === 1;\n\nlet chunkContext = '';\nif (!isFirstChunk) {\n  // Mid-conversation: Show previous chunks from THIS SESSION\n  const currentChunkText = transcript.transcript || '';\n  const previousChunks = accumulatedTranscript.replace(currentChunkText, '').trim();\n  \n  chunkContext = `\\n\\n## Streaming Context (Chunk ${chunkNumber} of Session)\\n**CRITICAL: This is chunk ${chunkNumber} of an ongoing voice stream.**\\n\\n**Previous parts from THIS session:**\\n\"${previousChunks}\"\\n\\n**Current addition (what just arrived):**\\n\"${currentChunkText}\"\\n\\n**Full accumulated transcript:**\\n\"${accumulatedTranscript}\"\\n\\n**IMPORTANT:**\\n- User is CONTINUING their thought from previous chunks\\n- Do NOT treat this as a new conversation\\n- Do NOT re-greet or re-introduce yourself\\n- Build naturally on the accumulated context\\n- Previous chunks: ${chunkNumber - 1}`;\n} else {\n  chunkContext = `\\n\\n## Session Context\\n**This is the START of a new conversation** (Chunk 1 of session).\\n- Fresh session - greeting appropriate if user greets first\\n- No accumulated transcript yet\\n- First words from user in this session`;\n}\n\n// Extract recent transcripts and responses\nconst recentInteractions = historyRows.slice(0, 4).map(row => ({\n  userSaid: (row.transcript_exact || '').toLowerCase().trim(),\n  botReplied: row.agent_output_raw || ''\n}));\n\n// Build conversation history for context\nlet conversationHistory = '';\nif (recentInteractions.length > 0) {\n  conversationHistory = '\\n\\n## Recent Conversation History (From Database):\\n';\n  recentInteractions.forEach((interaction, i) => {\n    conversationHistory += `${i + 1}. User: \"${interaction.userSaid}\"\\n   You said: \"${interaction.botReplied}\"\\n`;\n  });\n}\n\n// Check for similar recent responses to avoid\nconst recentResponses = recentInteractions.map(i => i.botReplied).filter(r => r);\nconst uniqueResponses = [...new Set(recentResponses)];\n\n// Check if user is continuing same topic\nconst currentLower = transcript.transcript.toLowerCase();\nconst lastUserMessage = recentInteractions[0]?.userSaid || '';\nconst isContinuation = currentLower.includes(lastUserMessage) || lastUserMessage.includes(currentLower);\n\n// Response timing from classifier\nconst timing = transcript.response_timing || {};\nconst urgency = timing.response_urgency || 'standard';\nconst isComplete = timing.is_complete_thought || false;\n\n// Session state from classifier\nconst sessionState = transcript.session_state || {};\nconst isFirstMessage = transcript.is_first_message || false;\nconst processingCount = sessionState.processing_count || 0;\nconst lastOrchestratorCues = sessionState.last_orchestrator_cues || '';\nconst pendingActions = sessionState.pending_actions || [];\n\n// Detect if this is an email request that needs an address\nconst needsEmailAddress = /send.*email|email.*to/i.test(currentLower) &&\n  !/[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\\\.[a-zA-Z]{2,}/.test(currentLower);\n\n// Check if we already asked for email address\nconst alreadyAskedForEmail = recentResponses.some(r =>\n  r.toLowerCase().includes('email address') ||\n  r.toLowerCase().includes('what email') ||\n  r.toLowerCase().includes('send that to')\n);\n\n// Build response guidance\nlet responseGuidance = '';\nif (needsEmailAddress && alreadyAskedForEmail) {\n  responseGuidance = `\\n\\n## IMPORTANT: You already asked for the email address!\\nThe user is still talking. They haven't given you an email address yet.\\nWAIT for them to provide an email address. Do NOT ask again.\\nSay something like: \"I'm ready when you have that email address.\" or \"Just let me know the recipient.\"`;\n} else if (isContinuation) {\n  responseGuidance = `\\n\\n## IMPORTANT: User is continuing their previous message.\\nThis appears to be a continuation of what they were saying.\\nDon't repeat your previous response - acknowledge they're still talking or wait for them to finish.`;\n}\n\n// Build Intent Markers explanation section\nconst intentMarkersSection = `## Understanding Intent Classification\\n\\nA fast classifier has ALREADY evaluated this transcript before reaching you. Here's what it determined:\\n\\n**Route Code:** ${transcript.route || 'unknown'}\\n- P=PROCESS (respond to user), W=WAIT (buffering/incomplete), L=LOG_ONLY (background)\\n\\n**Intent:** ${transcript.intent || 'unknown'}\\n- Detected: ${transcript.is_addressing_bot ? 'Bot is being addressed' : 'General conversation'}\\n\\n**Classification Flags (for reference):**\\nThese 7 binary flags were used to determine routing:\\n1. NEAR_END (1) - Sentence appears complete\\n2. REQUEST (2) - Contains action request\\n3. INCOMPLETE (4) - Partial/unfinished thought\\n4. TOOL_ACTIVE (8) - Action in progress\\n5. GREETING (16) - Opening greeting detected\\n6. BOT_ADDRESSED (32) - Bot name mentioned\\n7. FIRST_MSG (64) - Session start\\n\\nCurrent state: is_first_message=${isFirstMessage}, is_addressing_bot=${transcript.is_addressing_bot || false}`;\n\n// Build Session State section\nconst sessionStateSection = `## Session State (From Previous Chunks)\\n\\n**What you said in previous chunks:**\\n${lastOrchestratorCues ? `\"${lastOrchestratorCues}\"` : '(Nothing yet - this is the first chunk you\\'re responding to)'}\\n\\n**Pending actions from previous chunks:**\\n${pendingActions.length > 0 ? pendingActions.map(a => `- ${a}`).join('\\n') : '(No pending actions)'}\\n\\n**Session metrics:**\\n- Total chunks processed: ${processingCount}\\n- Current chunk number: ${chunkNumber}\\n- Session active: ${sessionState.session_start_time ? 'Yes (started ' + new Date(sessionState.session_start_time).toISOString() + ')' : 'Just starting'}\\n\\n**Continuity instructions:**\\n${lastOrchestratorCues && !isFirstMessage ?\\n`- You previously said: \"${lastOrchestratorCues}\"\\n- Build naturally on that response\\n- Don't repeat what you already said\\n- User is responding to YOUR previous statement` :\\n`- No previous bot responses in this session yet\\n- This is your first chance to speak`}`;\n\n// Build the complete system prompt\nconst systemPrompt = `You are a voice assistant in a Microsoft Teams meeting.\\n\\n## How This Works\\nYour text output is AUTOMATICALLY converted to speech and played in the meeting.\\nDo NOT describe what you'll say - just say it directly.\\n\\n${intentMarkersSection}\\n${chunkContext}\\n${sessionStateSection}\\n\\n## CRITICAL ANTI-REPEAT RULES\\n\\n**YOUR PREVIOUS RESPONSES (DO NOT SAY THESE AGAIN):**\\n${uniqueResponses.map((r, i) => `${i + 1}. \"${r}\"`).join('\\n')}\\n\\n**If you repeat ANY of the above responses, the user will hear the same thing twice. This is a BAD user experience.**\\n${responseGuidance}\\n\\n## Response Rules\\n\\nURGENCY: ${urgency.toUpperCase()} | COMPLETE THOUGHT: ${isComplete ? 'YES' : 'NO'}\\n\\n${urgency === 'wait' || urgency === 'none' ?\\n`⚠️ STAY SILENT - ${urgency === 'wait' ? 'incomplete sentence, wait for more' : 'background conversation'}\\nOutput nothing. This is correct behavior.` :\\n`Respond concisely (1-2 sentences). Your words will be spoken aloud.`}\\n\\n## Tools Available\\n- gmail_agent: Send emails (requires transcript + email_address)\\n- think: Internal reasoning (silent, user won't hear)\\n\\n## Email Workflow\\n1. If user asks to send email but no address: Ask for email address ONCE\\n2. If you already asked: WAIT for them to provide it\\n3. When you have both content and address: Call gmail_agent\\n4. Confirm when done: \\\"Email sent!\\\"\\n${conversationHistory}\\n\\n## Current Input\\nIntent: ${transcript.intent || 'unknown'}\\nSpeaker: ${transcript.speaker || 'unknown'}\\nMessage #${historyRows.length + 1}\\nIs first message this session: ${isFirstMessage ? 'YES' : 'NO'}\\nChunk #${chunkNumber} in current session\\nAccumulated transcript length: ${accumulatedTranscript.length} chars\\nCache used: ${transcript.use_cached_context ? 'YES' : 'NO'}\\n\\nRespond naturally, briefly, and NEVER repeat a previous response verbatim.`;\n\nreturn [{\n  json: {\n    user_input: transcript.transcript,\n    bot_id: transcript.bot_id,\n    is_final: transcript.is_final,\n    intent: transcript.intent,\n    current_state: historyRows[0]?.ai_analysis?.conversation_state || 'IDLE',\n    message_count: historyRows.length + 1,\n    session_id: transcript.bot_id + '_session',\n    received_at: transcript.received_at,\n    response_urgency: urgency,\n    is_complete_thought: isComplete,\n    is_continuation: isContinuation,\n    already_asked_for_email: alreadyAskedForEmail,\n    is_first_message: isFirstMessage,\n    processing_count: processingCount,\n    chunk_number: chunkNumber,\n    accumulated_transcript: accumulatedTranscript,\n    cache_hit: transcript.use_cached_context || false,\n    context_age_ms: transcript.context_age_ms || 0,\n    last_orchestrator_cues: lastOrchestratorCues,\n    pending_actions: pendingActions,\n    system_prompt: systemPrompt,\n    chat_input: transcript.transcript\n  }\n}];"
        },
        "id": "build-context-1",
        "name": "Build Agent Context",
        "type": "n8n-nodes-base.code",
        "position": [
          848,
          480
        ],
        "typeVersion": 2
      },
      {
        "parameters": {
          "promptType": "define",
          "text": "={{ $json.chat_input }}",
          "options": {
            "systemMessage": "={{ $json.system_prompt }}",
            "maxIterations": 5
          }
        },
        "type": "@n8n/n8n-nodes-langchain.agent",
        "typeVersion": 3,
        "position": [
          1024,
          480
        ],
        "id": "6b9b0552-8540-47fa-b65d-d2d46882fc5a",
        "name": "Orchestrator Agent"
      },
      {
        "parameters": {
          "model": "openai/gpt-4o-mini",
          "options": {}
        },
        "type": "@n8n/n8n-nodes-langchain.lmChatOpenRouter",
        "typeVersion": 1,
        "position": [
          912,
          720
        ],
        "id": "1dc8c729-f513-4140-94f1-db3ddf723700",
        "name": "OpenRouter Chat Model",
        "credentials": {
          "openRouterApi": {
            "id": "OPPAOWUbmkR2frSd",
            "name": "OpenRouter account"
          }
        }
      },
      {
        "parameters": {
          "description": "Send emails on behalf of the user. Provide the recipient's email address and what to say in the email.",
          "workflowId": {
            "__rl": true,
            "value": "kL0AP3CkRby6OmVb",
            "mode": "id"
          },
          "workflowInputs": {
            "mappingMode": "defineBelow",
            "value": {
              "transcript": "={{ $fromAI('transcript', 'The user request or message content for the email', 'string') }}",
              "email_address": "={{ $fromAI('email_address', 'The recipient email address to send to (REQUIRED)', 'string') }}",
              "context": "={{ {} }}",
              "bot_id": "={{ $('Build Agent Context').first().json.bot_id }}",
              "session_id": "={{ $('Build Agent Context').first().json.session_id }}"
            },
            "schema": [
              {
                "id": "transcript",
                "displayName": "transcript",
                "required": true,
                "defaultMatch": false,
                "canBeUsedToMatch": true,
                "display": true,
                "type": "string",
                "readOnly": false,
                "removed": false
              },
              {
                "id": "email_address",
                "displayName": "email_address",
                "required": true,
                "defaultMatch": false,
                "canBeUsedToMatch": true,
                "display": true,
                "type": "string",
                "readOnly": false,
                "removed": false
              },
              {
                "id": "context",
                "displayName": "context",
                "required": false,
                "defaultMatch": false,
                "canBeUsedToMatch": true,
                "display": true,
                "type": "object",
                "readOnly": false,
                "removed": false
              },
              {
                "id": "bot_id",
                "displayName": "bot_id",
                "required": true,
                "defaultMatch": false,
                "canBeUsedToMatch": true,
                "display": true,
                "type": "string",
                "readOnly": false,
                "removed": false
              },
              {
                "id": "session_id",
                "displayName": "session_id",
                "required": true,
                "defaultMatch": false,
                "canBeUsedToMatch": true,
                "display": true,
                "type": "string",
                "readOnly": false,
                "removed": false
              }
            ]
          }
        },
        "id": "gmail-tool-1",
        "name": "Gmail Agent Tool",
        "type": "@n8n/n8n-nodes-langchain.toolWorkflow",
        "position": [
          1376,
          784
        ],
        "typeVersion": 2.2
      },
      {
        "parameters": {},
        "id": "think-tool-1",
        "name": "Think Tool",
        "type": "@n8n/n8n-nodes-langchain.toolThink",
        "position": [
          1520,
          768
        ],
        "typeVersion": 1.1
      },
      {
        "parameters": {
          "jsCode": "// Build Immutable Log v2.1 - Enhanced with session_state and is_first_message\nconst agent = $('Orchestrator Agent').first().json;\nconst context = $('Build Agent Context').first().json;\nconst classifier = $('Process Transcript').first().json;\n\nlet ttsSuccess = false, sentenceCount = 0;\nlet ttsMessage = agent.output || '';\n\ntry {\n  const sentenceData = $('Split into Sentences').first();\n  if (sentenceData && sentenceData.json) {\n    sentenceCount = sentenceData.json.total_sentences || 1;\n    ttsSuccess = true;\n  }\n} catch (e) { sentenceCount = 1; }\n\ntry {\n  const sendResults = $('Send Sentence Audio').all();\n  if (sendResults && sendResults.length > 0) {\n    ttsSuccess = sendResults.every(r => !r.json.error);\n  }\n} catch (e) {}\n\nlet toolCalls = [];\ntry {\n  if (agent.intermediateSteps) {\n    toolCalls = agent.intermediateSteps.map(step => ({\n      tool: (step.action && step.action.tool) || 'unknown',\n      input: (step.action && step.action.toolInput) || {},\n      output: step.observation || null\n    }));\n  }\n  if (agent.steps && agent.steps.length > 0) {\n    toolCalls = agent.steps.map(step => ({\n      tool: (step.action && step.action.tool) || 'unknown',\n      input: (step.action && step.action.toolInput) || {},\n      output: step.observation || null\n    }));\n  }\n} catch (e) { toolCalls = []; }\n\ntoolCalls.push({\n  tool: 'chunked_tts',\n  input: { message: ttsMessage, sentence_count: sentenceCount },\n  output: ttsSuccess ? 'Sent ' + sentenceCount + ' audio chunks' : 'TTS failed'\n});\n\n// Update static data with orchestrator cues for next iteration\nconst staticData = $getWorkflowStaticData('global');\nif (staticData.botTranscripts && staticData.botTranscripts[context.bot_id]) {\n  // Store the AI output for next iteration's session_state\n  staticData.botTranscripts[context.bot_id].lastOrchestratorCues = agent.output || '';\n  // Track pending actions from tool calls\n  const pendingTools = toolCalls.filter(tc => \n    tc.tool !== 'chunked_tts' && tc.tool !== 'think' && \n    tc.output && tc.output.includes && tc.output.includes('pending')\n  ).map(tc => tc.tool);\n  staticData.botTranscripts[context.bot_id].pendingActions = pendingTools;\n}\n\nreturn {\n  transcript_exact: context.user_input || '',\n  agent_output_raw: agent.output || '',\n  tool_calls: toolCalls,\n  timestamps: {\n    received_at: context.received_at,\n    processed_at: Date.now(),\n    logged_at: new Date().toISOString()\n  },\n  session_id: context.session_id,\n  bot_id: context.bot_id,\n  classifier_route: classifier.route,\n  classifier_intent: classifier.intent,\n  tts_result: {\n    success: ttsSuccess,\n    audio_sent: ttsSuccess,\n    call_count: sentenceCount,\n    chunked: true,\n    source: 'sentence_loop'\n  },\n  workflow_source: 'orchestrator',\n  error_flags: {\n    agent_error: !agent.output,\n    tts_error: !ttsSuccess\n  },\n  // NEW: Pass session state and first message flag to logging sub-workflow\n  session_state: classifier.session_state || {\n    last_orchestrator_cues: '',\n    pending_actions: [],\n    processing_count: 0\n  },\n  is_first_message: classifier.is_first_message || false\n};"
        },
        "id": "log-1",
        "name": "Build Immutable Log",
        "type": "n8n-nodes-base.code",
        "position": [
          2000,
          528
        ],
        "typeVersion": 2
      },
      {
        "parameters": {
          "workflowId": {
            "__rl": true,
            "value": "8LX5tt3SkO8GNuLj",
            "mode": "id"
          },
          "options": {}
        },
        "id": "call-logging-agent",
        "name": "Call Logging Agent",
        "type": "n8n-nodes-base.executeWorkflow",
        "typeVersion": 1.2,
        "position": [
          2208,
          528
        ]
      },
      {
        "parameters": {
          "conditions": {
            "options": {
              "version": 2,
              "leftValue": "",
              "caseSensitive": true,
              "typeValidation": "strict"
            },
            "combinator": "and",
            "conditions": [
              {
                "id": "has-output",
                "operator": {
                  "type": "string",
                  "operation": "notEmpty"
                },
                "leftValue": "={{ $json.output }}",
                "rightValue": ""
              }
            ]
          },
          "options": {}
        },
        "id": "check-output-if",
        "name": "Check Agent Output",
        "type": "n8n-nodes-base.if",
        "typeVersion": 2.3,
        "position": [
          1392,
          496
        ]
      },
      {
        "parameters": {
          "jsCode": "// SENTENCE-LEVEL TTS CHUNKING\n// Split agent output into sentences for progressive audio delivery\nconst agentOutput = $('Orchestrator Agent').first().json.output || '';\nconst botId = $('Build Agent Context').first().json.bot_id;\n\nif (!agentOutput.trim()) {\n  return [{ json: { sentences: [], bot_id: botId, total_sentences: 0, skip_tts: true } }];\n}\n\n// Split by sentence boundaries\n// Matches: . ! ? followed by space or end of string\n// Preserves punctuation with the sentence\nconst sentencePattern = /[^.!?]*[.!?]+(?:\\s|$)/g;\nlet sentences = agentOutput.match(sentencePattern) || [agentOutput];\n\n// Clean up sentences\nsentences = sentences\n  .map(s => s.trim())\n  .filter(s => s.length > 0);\n\n// If no sentences found (no punctuation), treat as single chunk\nif (sentences.length === 0) {\n  sentences = [agentOutput.trim()];\n}\n\n// Return array of items - one per sentence\nconst items = sentences.map((sentence, index) => ({\n  json: {\n    sentence: sentence,\n    sentence_index: index,\n    total_sentences: sentences.length,\n    bot_id: botId,\n    is_first: index === 0,\n    is_last: index === sentences.length - 1,\n    full_output: agentOutput\n  }\n}));\n\nreturn items;"
        },
        "id": "split-sentences",
        "name": "Split into Sentences",
        "type": "n8n-nodes-base.code",
        "typeVersion": 2,
        "position": [
          912,
          200
        ]
      },
      {
        "parameters": {
          "jsCode": "// PARALLEL TTS GENERATION → SEQUENTIAL RECALL.AI DELIVERY\n// v2: Added bot status check before sending\n\nconst items = $input.all();\nif (!items.length) {\n  return [{ json: { success: false, error: 'No sentences to process' } }];\n}\n\nconst bot_id = items[0].json.bot_id;\nconst voice = items[0].json.voice || 'alloy';\n\nconst OPENAI_API_KEY = 'OPENAI_API_KEY_REDACTED';\nconst RECALL_API_KEY = '4f12c2c033fc1f0fe1e4ca2fcd0aad92b547ff43';\n\n// STEP 0: Check bot status first\nlet botActive = false;\nlet botStatus = 'unknown';\ntry {\n  const statusResponse = await this.helpers.httpRequest({\n    method: 'GET',\n    url: `https://us-west-2.recall.ai/api/v1/bot/${bot_id}/`,\n    headers: {\n      'Authorization': `Token ${RECALL_API_KEY}`\n    },\n    returnFullResponse: false\n  });\n  \n  // Check the last status in status_changes array\n  if (statusResponse.status_changes && statusResponse.status_changes.length > 0) {\n    const lastStatus = statusResponse.status_changes[statusResponse.status_changes.length - 1];\n    botStatus = lastStatus.code;\n    // Active states: in_call_recording, in_call_not_recording\n    botActive = ['in_call_recording', 'in_call_not_recording'].includes(botStatus);\n  }\n} catch (error) {\n  console.log(`Bot status check failed: ${error.message}`);\n  botStatus = 'check_failed';\n  botActive = false;\n}\n\nif (!botActive) {\n  return [{\n    json: {\n      ...items[0].json,\n      tts_summary: {\n        total_sentences: items.length,\n        tts_generated: 0,\n        tts_failed: 0,\n        audio_sent: 0,\n        send_failed: 0,\n        send_errors: [],\n        skipped_reason: `Bot not active (status: ${botStatus})`\n      }\n    }\n  }];\n}\n\n// STEP 1: Generate ALL TTS in parallel\nconst ttsPromises = items.map(async (item, index) => {\n  const sentence = item.json.sentence;\n  const sentenceIndex = item.json.sentence_index ?? index;\n  \n  try {\n    const response = await this.helpers.httpRequest({\n      method: 'POST',\n      url: 'https://api.openai.com/v1/audio/speech',\n      headers: {\n        'Authorization': `Bearer ${OPENAI_API_KEY}`,\n        'Content-Type': 'application/json'\n      },\n      body: JSON.stringify({\n        model: 'tts-1',\n        voice: voice,\n        input: sentence,\n        response_format: 'mp3'\n      }),\n      encoding: 'arraybuffer',\n      returnFullResponse: false\n    });\n    \n    const audio_base64 = Buffer.from(response).toString('base64');\n    \n    return {\n      sentenceIndex,\n      sentence,\n      audio_base64,\n      success: true\n    };\n  } catch (error) {\n    return {\n      sentenceIndex,\n      sentence,\n      error: error.message,\n      success: false\n    };\n  }\n});\n\nconst allAudio = await Promise.all(ttsPromises);\nconst failures = allAudio.filter(a => !a.success);\nconst successfulAudio = allAudio.filter(a => a.success);\nsuccessfulAudio.sort((a, b) => a.sentenceIndex - b.sentenceIndex);\n\n// STEP 2: Send to Recall.ai SEQUENTIALLY\nconst sendResults = [];\nfor (const audio of successfulAudio) {\n  try {\n    await this.helpers.httpRequest({\n      method: 'POST',\n      url: `https://us-west-2.recall.ai/api/v1/bot/${bot_id}/output_audio/`,\n      headers: {\n        'Authorization': `Token ${RECALL_API_KEY}`,\n        'Content-Type': 'application/json'\n      },\n      body: JSON.stringify({\n        kind: 'mp3',\n        b64_data: audio.audio_base64\n      }),\n      returnFullResponse: false\n    });\n    \n    sendResults.push({\n      sentenceIndex: audio.sentenceIndex,\n      sent: true\n    });\n  } catch (error) {\n    sendResults.push({\n      sentenceIndex: audio.sentenceIndex,\n      sent: false,\n      error: error.message\n    });\n  }\n}\n\nreturn [{\n  json: {\n    ...items[0].json,\n    tts_summary: {\n      total_sentences: items.length,\n      tts_generated: successfulAudio.length,\n      tts_failed: failures.length,\n      audio_sent: sendResults.filter(r => r.sent).length,\n      send_failed: sendResults.filter(r => !r.sent).length,\n      send_errors: sendResults.filter(r => !r.sent).map(r => r.error),\n      bot_status: botStatus\n    }\n  }\n}];"
        },
        "id": "parallel-tts-send",
        "name": "Parallel TTS & Send",
        "type": "n8n-nodes-base.code",
        "typeVersion": 2,
        "position": [
          1808,
          384
        ]
      },
      {
        "id": "ultra-fast-prerouter",
        "name": "Ultra-Fast Pre-Router",
        "type": "n8n-nodes-base.code",
        "typeVersion": 2,
        "position": [
          100,
          304
        ],
        "parameters": {
          "mode": "runOnceForAllItems",
          "language": "javaScript",
          "jsCode": "// ============================================================\n// ULTRA-FAST PRE-ROUTER - Sub-10ms Heuristic Classifier\n// ============================================================\n// PURPOSE: Fast-path routing to avoid heavy processing for obvious cases\n// GOAL: <10ms execution using pure heuristics, NO DB, NO API calls\n// ============================================================\n\nconst startTime = Date.now();\n\n// Extract webhook data\nconst body = $input.first().json.body || $input.first().json;\nconst transcript = (body.transcript || '').trim();\nconst bot_id = body.bot_id || 'unknown';\nconst session_id = body.session_id || '';\n\n// ============================================================\n// HEURISTIC ANALYSIS (all sub-millisecond operations)\n// ============================================================\n\n// 1. Empty/whitespace detection\nconst isEmpty = !transcript || transcript.length === 0;\nconst isWhitespaceOnly = /^\\s*$/.test(transcript);\n\n// 2. Word analysis\nconst words = transcript.split(/\\s+/).filter(w => w.length > 0);\nconst wordCount = words.length;\n\n// 3. Punctuation detection (end-of-thought indicators)\nconst hasEndPunctuation = /[.!?]\\s*$/.test(transcript);\nconst hasMidPunctuation = /[.!?,;:]/.test(transcript.slice(0, -1));\nconst punctuationCount = (transcript.match(/[.!?,;:]/g) || []).length;\n\n// 4. Bot name detection (phonetic variations)\n// Matches: \"SYNRG\", \"Synergy\", \"synrgy\", \"synergy bot\", etc.\nconst botNamePattern = /\\b(synr?g[yie]?|synergy)\\s*(bot)?\\b/i;\nconst isAddressingBot = botNamePattern.test(transcript);\n\n// 5. Greeting detection\nconst greetingPattern = /^(h(i|ey|ello)|good\\s*(morning|afternoon|evening)|what'?s\\s*up|yo\\b)/i;\nconst isGreeting = greetingPattern.test(transcript) && wordCount <= 5;\n\n// 6. Question detection\nconst isQuestion = /\\?\\s*$/.test(transcript) || \n                   /^(what|where|when|why|how|who|can|could|would|will|is|are|do|does)\\b/i.test(transcript);\n\n// 7. Request/command detection\nconst requestPattern = /\\b(send|email|help|remind|schedule|book|create|make|please|can you|could you)\\b/i;\nconst hasRequest = requestPattern.test(transcript);\n\n// 8. Filler/noise detection\nconst fillerPattern = /^(um+|uh+|ah+|er+|hmm+|like|so|well|okay|ok)\\s*$/i;\nconst isFillerOnly = fillerPattern.test(transcript);\n\n// 9. Continuation detection (no greeting, mid-sentence start)\nconst startsLowercase = /^[a-z]/.test(transcript);\nconst startsMidThought = startsLowercase && !isGreeting && wordCount > 2;\n\n// ============================================================\n// CONFIDENCE SCORING\n// ============================================================\n\nlet completenessScore = 0;\n\n// Positive signals (thought is complete)\nif (hasEndPunctuation) completenessScore += 0.4;\nif (wordCount >= 7) completenessScore += 0.2;\nif (isQuestion) completenessScore += 0.2;\nif (hasRequest) completenessScore += 0.15;\nif (isAddressingBot) completenessScore += 0.15;\n\n// Negative signals (thought is incomplete)\nif (wordCount < 3) completenessScore -= 0.3;\nif (startsMidThought && !hasEndPunctuation) completenessScore -= 0.2;\nif (transcript.endsWith(',')) completenessScore -= 0.3;\nif (/\\b(and|but|or|so|then|because|if|when|while)\\s*$/i.test(transcript)) completenessScore -= 0.4;\n\n// Clamp to 0-1 range\nconst completeness = Math.max(0, Math.min(1, completenessScore + 0.5));\n\n// ============================================================\n// ROUTING DECISION (Graduated Response Modes)\n// ============================================================\n// Routes:\n//   SILENT       - No action, don't even log heavily\n//   BUFFER       - Accumulate transcript, wait for more\n//   ACKNOWLEDGE  - Quick acknowledgment (\"I hear you\")\n//   QUICK_REPLY  - Simple cached/template response\n//   FULL_PROCESS - Full agent processing required\n// ============================================================\n\nlet preRoute = 'BUFFER'; // Default: wait for more\nlet routeReason = '';\nlet urgency = 'low';\n\n// Decision tree (order matters - most specific first)\n\nif (isEmpty || isWhitespaceOnly) {\n  preRoute = 'SILENT';\n  routeReason = 'empty_transcript';\n  urgency = 'none';\n}\nelse if (isFillerOnly) {\n  preRoute = 'SILENT';\n  routeReason = 'filler_noise';\n  urgency = 'none';\n}\nelse if (wordCount === 1 && !isAddressingBot && !isGreeting) {\n  preRoute = 'SILENT';\n  routeReason = 'single_word_noise';\n  urgency = 'none';\n}\nelse if (isAddressingBot && hasRequest) {\n  // Bot addressed + clear request = immediate processing\n  preRoute = 'FULL_PROCESS';\n  routeReason = 'bot_addressed_with_request';\n  urgency = 'immediate';\n}\nelse if (isAddressingBot && (isQuestion || isGreeting)) {\n  // Bot addressed + question or greeting = process\n  preRoute = 'FULL_PROCESS';\n  routeReason = 'bot_addressed_directly';\n  urgency = 'high';\n}\nelse if (isGreeting && wordCount <= 3) {\n  // Simple greeting - quick template response\n  preRoute = 'QUICK_REPLY';\n  routeReason = 'simple_greeting';\n  urgency = 'standard';\n}\nelse if (hasRequest && hasEndPunctuation) {\n  // Clear request with complete thought\n  preRoute = 'FULL_PROCESS';\n  routeReason = 'complete_request';\n  urgency = 'high';\n}\nelse if (completeness >= 0.7 && wordCount >= 5) {\n  // High confidence complete thought\n  preRoute = 'FULL_PROCESS';\n  routeReason = 'complete_thought';\n  urgency = 'standard';\n}\nelse if (completeness >= 0.5 && wordCount >= 7) {\n  // Moderate confidence but enough content\n  preRoute = 'FULL_PROCESS';\n  routeReason = 'sufficient_content';\n  urgency = 'standard';\n}\nelse if (isAddressingBot) {\n  // Bot addressed but unclear intent - acknowledge\n  preRoute = 'ACKNOWLEDGE';\n  routeReason = 'bot_addressed_unclear';\n  urgency = 'standard';\n}\nelse if (wordCount >= 3 && wordCount < 6 && !hasEndPunctuation) {\n  // Short phrase, no punctuation - buffer and wait\n  preRoute = 'BUFFER';\n  routeReason = 'incomplete_phrase';\n  urgency = 'low';\n}\nelse if (wordCount < 3) {\n  preRoute = 'BUFFER';\n  routeReason = 'too_short';\n  urgency = 'low';\n}\n\n// ============================================================\n// STATIC DATA: Session Tracking\n// ============================================================\nconst staticData = $getWorkflowStaticData('global');\nstaticData.preRouterStats = staticData.preRouterStats || {};\nconst stats = staticData.preRouterStats;\n\n// Track routing decisions for learning\nstats[preRoute] = (stats[preRoute] || 0) + 1;\nstats.totalCalls = (stats.totalCalls || 0) + 1;\n\n// Session tracking for greeting detection\nstaticData.sessionInfo = staticData.sessionInfo || {};\nconst sessionKey = `${bot_id}_${session_id}`;\nconst isFirstMessage = !staticData.sessionInfo[sessionKey];\nif (isFirstMessage) {\n  staticData.sessionInfo[sessionKey] = { firstSeen: Date.now(), messageCount: 0 };\n}\nstaticData.sessionInfo[sessionKey].messageCount++;\nstaticData.sessionInfo[sessionKey].lastSeen = Date.now();\n\n// ============================================================\n// OUTPUT\n// ============================================================\nconst executionTime = Date.now() - startTime;\n\nreturn [{\n  json: {\n    // Pass through original data\n    ...body,\n    \n    // Pre-router classification\n    pre_route: preRoute,\n    route_reason: routeReason,\n    urgency: urgency,\n    \n    // Heuristic analysis results\n    heuristics: {\n      word_count: wordCount,\n      has_end_punctuation: hasEndPunctuation,\n      is_addressing_bot: isAddressingBot,\n      is_greeting: isGreeting,\n      is_question: isQuestion,\n      has_request: hasRequest,\n      is_filler: isFillerOnly,\n      completeness_score: Math.round(completeness * 100) / 100,\n      is_first_message: isFirstMessage\n    },\n    \n    // Performance tracking\n    pre_router_ms: executionTime,\n    \n    // Intent markers for feedback loop\n    intent_markers: {\n      near_end_of_thought: completeness >= 0.6,\n      request_detected: hasRequest,\n      bot_addressed: isAddressingBot,\n      greeting_detected: isGreeting,\n      question_detected: isQuestion\n    }\n  }\n}];"
        }
      },
      {
        "id": "pre-route-switch",
        "name": "Pre-Route Switch",
        "type": "n8n-nodes-base.switch",
        "typeVersion": 3,
        "position": [
          208,
          304
        ],
        "parameters": {
          "rules": {
            "values": [
              {
                "conditions": {
                  "options": {
                    "version": 2,
                    "leftValue": "",
                    "caseSensitive": true,
                    "typeValidation": "strict"
                  },
                  "combinator": "and",
                  "conditions": [
                    {
                      "id": "rule-silent",
                      "operator": {
                        "type": "string",
                        "operation": "equals"
                      },
                      "leftValue": "={{ $json.pre_route }}",
                      "rightValue": "SILENT"
                    }
                  ]
                },
                "renameOutput": true,
                "outputKey": "SILENT"
              },
              {
                "conditions": {
                  "options": {
                    "version": 2,
                    "leftValue": "",
                    "caseSensitive": true,
                    "typeValidation": "strict"
                  },
                  "combinator": "and",
                  "conditions": [
                    {
                      "id": "rule-buffer",
                      "operator": {
                        "type": "string",
                        "operation": "equals"
                      },
                      "leftValue": "={{ $json.pre_route }}",
                      "rightValue": "BUFFER"
                    }
                  ]
                },
                "renameOutput": true,
                "outputKey": "BUFFER"
              },
              {
                "conditions": {
                  "options": {
                    "version": 2,
                    "leftValue": "",
                    "caseSensitive": true,
                    "typeValidation": "strict"
                  },
                  "combinator": "and",
                  "conditions": [
                    {
                      "id": "rule-ack",
                      "operator": {
                        "type": "string",
                        "operation": "equals"
                      },
                      "leftValue": "={{ $json.pre_route }}",
                      "rightValue": "ACKNOWLEDGE"
                    }
                  ]
                },
                "renameOutput": true,
                "outputKey": "ACKNOWLEDGE"
              },
              {
                "conditions": {
                  "options": {
                    "version": 2,
                    "leftValue": "",
                    "caseSensitive": true,
                    "typeValidation": "strict"
                  },
                  "combinator": "and",
                  "conditions": [
                    {
                      "id": "rule-quick",
                      "operator": {
                        "type": "string",
                        "operation": "equals"
                      },
                      "leftValue": "={{ $json.pre_route }}",
                      "rightValue": "QUICK_REPLY"
                    }
                  ]
                },
                "renameOutput": true,
                "outputKey": "QUICK_REPLY"
              },
              {
                "conditions": {
                  "options": {
                    "version": 2,
                    "leftValue": "",
                    "caseSensitive": true,
                    "typeValidation": "strict"
                  },
                  "combinator": "and",
                  "conditions": [
                    {
                      "id": "rule-full",
                      "operator": {
                        "type": "string",
                        "operation": "equals"
                      },
                      "leftValue": "={{ $json.pre_route }}",
                      "rightValue": "FULL_PROCESS"
                    }
                  ]
                },
                "renameOutput": true,
                "outputKey": "FULL_PROCESS"
              }
            ]
          },
          "options": {
            "fallbackOutput": "extra"
          }
        }
      },
      {
        "id": "acknowledge-handler",
        "name": "Quick Acknowledge",
        "type": "n8n-nodes-base.code",
        "typeVersion": 2,
        "position": [
          672,
          64
        ],
        "parameters": {
          "mode": "runOnceForAllItems",
          "language": "javaScript",
          "jsCode": "// QUICK ACKNOWLEDGE - Fast response for unclear bot addressing\nconst input = $input.first().json;\nconst ackOptions = [\"I'm listening...\", \"Go ahead...\", \"Yes?\", \"I hear you...\"];\nconst acknowledgment = ackOptions[Date.now() % ackOptions.length];\n\nreturn [{\n  json: {\n    ...input,\n    response_type: 'acknowledge',\n    response_text: acknowledgment,\n    should_speak: true,\n    route_taken: 'ACKNOWLEDGE'\n  }\n}];"
        }
      },
      {
        "id": "quick-reply-handler",
        "name": "Quick Reply",
        "type": "n8n-nodes-base.code",
        "typeVersion": 2,
        "position": [
          672,
          176
        ],
        "parameters": {
          "mode": "runOnceForAllItems",
          "language": "javaScript",
          "jsCode": "// QUICK REPLY - Template response for simple greetings\nconst input = $input.first().json;\nconst heuristics = input.heuristics || {};\nconst staticData = $getWorkflowStaticData('global');\nconst sessionKey = `${input.bot_id}_${input.session_id || ''}`;\n\nlet response = '';\nif (heuristics.is_greeting) {\n  const greetings = [\"Hello! How can I help?\", \"Hi there! What can I do for you?\", \"Hey! I'm ready to help.\"];\n  response = greetings[Date.now() % greetings.length];\n  staticData.greetingsSent = staticData.greetingsSent || {};\n  staticData.greetingsSent[sessionKey] = Date.now();\n} else {\n  response = \"I'm here. How can I help?\";\n}\n\nreturn [{\n  json: {\n    ...input,\n    response_type: 'quick_reply',\n    response_text: response,\n    should_speak: true,\n    route_taken: 'QUICK_REPLY'\n  }\n}];"
        }
      }
    ],
    "connections": {
      "Process Transcript": {
        "main": [
          [
            {
              "node": "Route Switch",
              "type": "main",
              "index": 0
            }
          ]
        ]
      },
      "Route Switch": {
        "main": [
          [
            {
              "node": "Log Silent Transcript",
              "type": "main",
              "index": 0
            }
          ],
          [
            {
              "node": "Wait Log Only",
              "type": "main",
              "index": 0
            }
          ],
          [
            {
              "node": "Log Listen Transcript",
              "type": "main",
              "index": 0
            }
          ],
          [
            {
              "node": "Load Bot State",
              "type": "main",
              "index": 0
            }
          ]
        ]
      },
      "Wait Log Only": {
        "main": [
          [
            {
              "node": "Log Wait Transcript",
              "type": "main",
              "index": 0
            }
          ]
        ]
      },
      "Build Agent Context": {
        "main": [
          [
            {
              "node": "Orchestrator Agent",
              "type": "main",
              "index": 0
            }
          ]
        ]
      },
      "OpenRouter Chat Model": {
        "ai_languageModel": [
          [
            {
              "node": "Orchestrator Agent",
              "type": "ai_languageModel",
              "index": 0
            }
          ]
        ]
      },
      "Gmail Agent Tool": {
        "ai_tool": [
          [
            {
              "node": "Orchestrator Agent",
              "type": "ai_tool",
              "index": 0
            }
          ]
        ]
      },
      "Think Tool": {
        "ai_tool": [
          [
            {
              "node": "Orchestrator Agent",
              "type": "ai_tool",
              "index": 0
            }
          ]
        ]
      },
      "Build Immutable Log": {
        "main": [
          [
            {
              "node": "Call Logging Agent",
              "type": "main",
              "index": 0
            }
          ]
        ]
      },
      "Load Bot State": {
        "main": [
          [
            {
              "node": "Build Agent Context",
              "type": "main",
              "index": 0
            }
          ]
        ]
      },
      "Orchestrator Agent": {
        "main": [
          [
            {
              "node": "Check Agent Output",
              "type": "main",
              "index": 0
            }
          ]
        ]
      },
      "Check Agent Output": {
        "main": [
          [
            {
              "node": "Split into Sentences",
              "type": "main",
              "index": 0
            }
          ],
          [
            {
              "node": "Build Immutable Log",
              "type": "main",
              "index": 0
            }
          ]
        ]
      },
      "Split into Sentences": {
        "main": [
          [
            {
              "node": "Parallel TTS & Send",
              "type": "main",
              "index": 0
            }
          ]
        ]
      },
      "Parallel TTS & Send": {
        "main": [
          [
            {
              "node": "Build Immutable Log",
              "type": "main",
              "index": 0
            }
          ]
        ]
      },
      "Webhook": {
        "main": [
          [
            {
              "node": "Ultra-Fast Pre-Router",
              "type": "main",
              "index": 0
            }
          ]
        ]
      },
      "Ultra-Fast Pre-Router": {
        "main": [
          [
            {
              "node": "Pre-Route Switch",
              "type": "main",
              "index": 0
            }
          ]
        ]
      },
      "Pre-Route Switch": {
        "0": [
          [
            {
              "node": "Log Silent Transcript",
              "type": "0",
              "index": 0
            }
          ]
        ],
        "1": [
          [
            {
              "node": "Wait Log Only",
              "type": "1",
              "index": 0
            }
          ]
        ],
        "4": [
          [
            {
              "node": "Process Transcript",
              "type": "4",
              "index": 0
            }
          ]
        ],
        "main": [
          [],
          [],
          [
            {
              "node": "Quick Acknowledge",
              "type": "main",
              "index": 0
            }
          ],
          [
            {
              "node": "Quick Reply",
              "type": "main",
              "index": 0
            }
          ]
        ]
      },
      "Quick Acknowledge": {
        "main": [
          [
            {
              "node": "Split into Sentences",
              "type": "main",
              "index": 0
            }
          ]
        ]
      },
      "Quick Reply": {
        "main": [
          [
            {
              "node": "Split into Sentences",
              "type": "main",
              "index": 0
            }
          ]
        ]
      }
    },
    "authors": "Jay Connor",
    "name": null,
    "description": null,
    "autosaved": false,
    "workflowPublishHistory": [
      {
        "createdAt": "2026-01-10T00:46:18.449Z",
        "id": 234,
        "workflowId": "d3CxEaYk5mkC8sLo",
        "versionId": "59850685-126a-44a8-8eb2-5cd130fb63d3",
        "event": "activated",
        "userId": "cd6f3efb-1d17-4b28-b2dc-bb38f830be30"
      }
    ]
  }
}
