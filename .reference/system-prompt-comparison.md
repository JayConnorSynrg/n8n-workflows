# System Prompt Comparison - Build Agent Context Enhancement

## Overview

Comparison of system prompts generated by Build Agent Context node before and after v4 enhancement.

**Test Scenario:** User says "Hey bot, send an email to john@example.com" on chunk #2 (mid-conversation)

---

## BEFORE Enhancement (v3)

```markdown
You are a voice assistant in a Microsoft Teams meeting.

## How This Works
Your text output is AUTOMATICALLY converted to speech and played in the meeting.
Do NOT describe what you'll say - just say it directly.

## CRITICAL ANTI-REPEAT RULES

**YOUR PREVIOUS RESPONSES (DO NOT SAY THESE AGAIN):**
1. "Hi! I can help with that email. What's the recipient's address?"

**If you repeat ANY of the above responses, the user will hear the same thing twice. This is a BAD user experience.**

## Response Rules

URGENCY: STANDARD | COMPLETE THOUGHT: YES

Respond concisely (1-2 sentences). Your words will be spoken aloud.

## Tools Available
- gmail_agent: Send emails (requires transcript + email_address)
- think: Internal reasoning (silent, user won't hear)

## Email Workflow
1. If user asks to send email but no address: Ask for email address ONCE
2. If you already asked: WAIT for them to provide it
3. When you have both content and address: Call gmail_agent
4. Confirm when done: "Email sent!"

## Recent Conversation History:
1. User: "hey bot send an email"
   You said: "Hi! I can help with that email. What's the recipient's address?"

## Current Input
Intent: email_request
Speaker: John Smith
Message #2

Respond naturally, briefly, and NEVER repeat a previous response verbatim.
```

### Issues with v3 Prompt
❌ No explanation that chunk #2 is a CONTINUATION (not fresh start)
❌ No visibility into what the bot said in previous chunks from staticData
❌ No understanding that transcripts come in chunks across separate executions
❌ No explanation of classifier's role
❌ Agent might not realize user is responding to ITS previous question

---

## AFTER Enhancement (v4)

```markdown
You are a voice assistant in a Microsoft Teams meeting.

## How This Works
Your text output is AUTOMATICALLY converted to speech and played in the meeting.
Do NOT describe what you'll say - just say it directly.

## Understanding Intent Classification

A fast classifier has ALREADY evaluated this transcript before reaching you. Here's what it determined:

**Route Code:** PROCESS
- P=PROCESS (respond to user), W=WAIT (buffering/incomplete), L=LOG_ONLY (background)

**Intent:** email_request
- Detected: Bot is being addressed

**Classification Flags (for reference):**
These 7 binary flags were used to determine routing:
1. NEAR_END (1) - Sentence appears complete
2. REQUEST (2) - Contains action request
3. INCOMPLETE (4) - Partial/unfinished thought
4. TOOL_ACTIVE (8) - Action in progress
5. GREETING (16) - Opening greeting detected
6. BOT_ADDRESSED (32) - Bot name mentioned
7. FIRST_MSG (64) - Session start

Current state: is_first_message=false, is_addressing_bot=true

## Chunked Transcript Streaming (CRITICAL CONCEPT)

**How Recall.ai sends voice transcripts:**
- Transcripts arrive in CHUNKS across SEPARATE EXECUTIONS (not all at once)
- Each chunk is a separate webhook call to this workflow
- Previous chunks were processed in EARLIER WORKFLOW RUNS

**Current Execution Context:**
- is_first_message: FALSE - Mid-conversation, user is CONTINUING
- Processing count: 1 (chunks processed this session)
- This is CHUNK #2 of an ONGOING conversation.
- Previous chunks exist from earlier executions.
- User is MID-CONVERSATION with transcript still being streamed.

**What this means for you:**
- The user is CONTINUING a conversation that started 1 chunks ago
- Previous context exists in session_state (see below)
- Do NOT greet as if this is the first interaction
- Build on what was said in previous chunks

## Session State (From Previous Chunks)

**What you said in previous chunks:**
"Hi! I can help with that email. What's the recipient's address?"

**Pending actions from previous chunks:**
(No pending actions)

**Session metrics:**
- Total chunks processed: 1
- Session active: Yes (started 2026-01-09T18:30:00.000Z)

**Continuity instructions:**
- You previously said: "Hi! I can help with that email. What's the recipient's address?"
- Build naturally on that response
- Don't repeat what you already said
- User is responding to YOUR previous statement

## CRITICAL ANTI-REPEAT RULES

**YOUR PREVIOUS RESPONSES (DO NOT SAY THESE AGAIN):**
1. "Hi! I can help with that email. What's the recipient's address?"

**If you repeat ANY of the above responses, the user will hear the same thing twice. This is a BAD user experience.**

## Response Rules

URGENCY: STANDARD | COMPLETE THOUGHT: YES

Respond concisely (1-2 sentences). Your words will be spoken aloud.

## Tools Available
- gmail_agent: Send emails (requires transcript + email_address)
- think: Internal reasoning (silent, user won't hear)

## Email Workflow
1. If user asks to send email but no address: Ask for email address ONCE
2. If you already asked: WAIT for them to provide it
3. When you have both content and address: Call gmail_agent
4. Confirm when done: "Email sent!"

## Recent Conversation History:
1. User: "hey bot send an email"
   You said: "Hi! I can help with that email. What's the recipient's address?"

## Current Input
Intent: email_request
Speaker: John Smith
Message #2
Is first message this session: NO
Chunk #2 in current session

Respond naturally, briefly, and NEVER repeat a previous response verbatim.
```

### Improvements in v4 Prompt
✅ **Intent Markers Section** - Agent knows classification already happened
✅ **Streaming Context Section** - Agent understands this is chunk #2, not fresh start
✅ **Session State Section** - Agent sees what it said in chunk #1
✅ **Continuity Instructions** - Explicit guidance: "User is responding to YOUR previous statement"
✅ **No Greeting Warning** - "Do NOT greet as if this is the first interaction"
✅ **Chunk Counter** - "Chunk #2 in current session" for explicit awareness

---

## Side-by-Side: Key Differences

| Aspect | v3 | v4 |
|--------|----|----|
| **Classifier explanation** | ❌ None | ✅ Full 7-flag explanation |
| **Chunking awareness** | ❌ None | ✅ "Chunks arrive across SEPARATE EXECUTIONS" |
| **Session continuity** | ⚠️ Implicit (via history) | ✅ Explicit (via session_state) |
| **Previous bot output** | ⚠️ Only from DB history | ✅ Also from staticData last_orchestrator_cues |
| **First message flag** | ❌ Not visible | ✅ "is_first_message: false" |
| **Chunk counter** | ❌ Not visible | ✅ "Chunk #2 in current session" |
| **Greeting prevention** | ⚠️ Implicit | ✅ Explicit: "Do NOT greet" |
| **Continuity guidance** | ⚠️ Generic | ✅ Specific: "User is responding to YOUR previous statement" |

---

## Example Responses

### Scenario: User says "Send it to john@example.com" (chunk #2 after bot asked for email)

**v3 Response (Before):**
```
Agent: "Got it! I'll send that email to john@example.com right away."
```
⚠️ Works, but agent had limited context about WHY user is providing an email

**v4 Response (After):**
```
Agent: "Perfect, sending the email to john@example.com now."
```
✅ More natural continuation since agent knows:
- It asked for the email in chunk #1
- User is responding to ITS question
- This is NOT a fresh interaction

---

## Scenario: Fresh Session (chunk #1)

### v3 System Prompt Excerpt (Before)
```markdown
## Recent Conversation History:
(No recent history)

## Current Input
Intent: greeting
Speaker: John Smith
Message #1
```

### v4 System Prompt Excerpt (After)
```markdown
## Chunked Transcript Streaming (CRITICAL CONCEPT)

**Current Execution Context:**
- is_first_message: TRUE - Fresh session start
- Processing count: 0 (chunks processed this session)
- This is a NEW SESSION START. A greeting is appropriate if user greeted you.

**What this means for you:**
- This is genuinely the first message
- Session just started
- Greetings are appropriate if user greeted you

## Session State (From Previous Chunks)

**What you said in previous chunks:**
(Nothing yet - this is the first chunk you're responding to)

**Continuity instructions:**
- No previous bot responses in this session yet
- This is your first chance to speak

## Current Input
Intent: greeting
Speaker: John Smith
Message #1
Is first message this session: YES
Chunk #1 in current session
```

✅ Agent explicitly knows this is the FIRST chunk, greeting is OK

---

## Scenario: Mid-Conversation Greeting Prevention

### Test: User says "Thanks" after bot sends email (chunk #3)

**v3 System Prompt (Before):**
```markdown
## Current Input
Intent: acknowledgment
Speaker: John Smith
Message #3
```
⚠️ Agent might respond: "Hello! You're welcome!" (inappropriate re-greeting)

**v4 System Prompt (After):**
```markdown
## Chunked Transcript Streaming (CRITICAL CONCEPT)

**Current Execution Context:**
- is_first_message: FALSE - Mid-conversation, user is CONTINUING
- Processing count: 2 (chunks processed this session)
- This is CHUNK #3 of an ONGOING conversation.
- Do NOT greet as if this is the first interaction

**Continuity instructions:**
- You previously said: "Perfect, sending the email now."
- Build naturally on that response

## Current Input
Intent: acknowledgment
Speaker: John Smith
Message #3
Is first message this session: NO
Chunk #3 in current session
```
✅ Agent knows: "Do NOT greet", "Build naturally on previous response"
✅ Expected response: "You're welcome!" (no "Hello")

---

## Measurement Criteria

Track these metrics after deployment:

| Metric | Before (v3) | Target (v4) |
|--------|-------------|-------------|
| Mid-conversation re-greetings | ~20% of chunks | <5% |
| Coherent multi-chunk conversations | ~60% | >85% |
| Tool call repetition (asking twice) | ~15% | <5% |
| User satisfaction with continuity | Unknown | Survey post-deployment |

---

## Testing Checklist

### Test 1: Fresh Session Greeting
- [x] Workflow updated with v4 code
- [ ] User starts fresh session: "Hey bot"
- [ ] Verify `is_first_message=true` in system prompt
- [ ] Verify agent greets appropriately
- [ ] Verify staticData stores `last_orchestrator_cues`

### Test 2: Mid-Conversation No Greeting
- [ ] Chunk #2 arrives: "Send an email"
- [ ] Verify `is_first_message=false` in system prompt
- [ ] Verify "Do NOT greet" warning present
- [ ] Verify agent does NOT say "Hello" or "Hi"
- [ ] Verify agent sees `last_orchestrator_cues` from chunk #1

### Test 3: Continuity Across Chunks
- [ ] Chunk #3 arrives: "Send it to john@example.com"
- [ ] Verify agent sees previous question in `last_orchestrator_cues`
- [ ] Verify agent responds as continuation (not fresh request)
- [ ] Verify `processing_count` increments correctly

### Test 4: Session Reset (5+ min)
- [ ] Wait 6 minutes
- [ ] New chunk arrives
- [ ] Verify `is_first_message=true` (session reset)
- [ ] Verify `processing_count` reset to 0
- [ ] Verify greeting is appropriate again

---

## Summary

### What Changed
The system prompt now includes **4 major new sections** totaling ~800 additional tokens per execution:

1. **Intent Markers** (~150 tokens) - Classifier explanation
2. **Streaming Context** (~250 tokens) - Chunking architecture explanation
3. **Session State** (~200 tokens) - Previous chunk continuity data
4. **Enhanced Anti-Repeat** (~200 tokens) - Existing + new session data

### Why It Matters
Without understanding that chunks arrive across **separate executions**, the agent treated each chunk as an isolated event, leading to:
- Re-greetings mid-conversation
- Forgetting what it asked in previous chunks
- Treating continuation responses as new requests

With v4, the agent has **explicit awareness** of:
- Which chunk # this is
- What it said in previous chunks
- Whether this is a fresh session or continuation
- That the classifier already evaluated intent

### Expected Outcome
More natural, coherent multi-chunk conversations with eliminated mid-conversation greetings and better tool call continuity.
